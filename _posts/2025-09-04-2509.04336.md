---
layout: post
title:  "Gravitational-wave inference at GPU speed: A bilby-like nested sampling kernel within blackjax-ns"
date:   2025-09-04
categories: papers
---
![AI generated image](/assets/images/posts/2025-09-04-2509.04336.png)

<!-- BEGINNING OF GENERATED POST -->
The era of gravitational-wave (GW) astronomy has opened a new window to the cosmos, but analyzing the torrent of data from observatories like LIGO, Virgo, and KAGRA presents a significant computational challenge. In our latest paper, "[Gravitational-wave inference at GPU speed: A bilby-like nested sampling kernel within blackjax-ns](https://arxiv.org/abs/2509.04336)," led by [Metha Prathaban](https://github.com/mrosep) and co-authored by [David Yallup](https://www.linkedin.com/in/dyallup/), [James Alvey](https://www.kicc.cam.ac.uk/staff/dr-james-alvey), [Ming Yang](https://willhandley.co.uk/), [Will Templeton](https://willhandley.co.uk/), and [Will Handley](https://willhandley.co.uk/), we tackle this bottleneck head-on by porting a cornerstone algorithm of GW analysis to modern, massively parallel hardware.

### The Challenge: A CPU Bottleneck
Bayesian inference is the gold standard for extracting astrophysical insights from GW signals, allowing us to estimate the parameters of colliding black holes and neutron stars. Community-standard software packages like `bilby` ([10.3847/1538-4365/ab06fc](https://doi.org/10.3847/1538-4365/ab06fc)) and `dynesty` ([10.1093/mnras/staa278](https://doi.org/10.1093/mnras/staa278)) have proven incredibly robust for this task. However, these frameworks are predominantly designed for CPUs, and a single analysis can require millions of likelihood evaluations, consuming hundreds of CPU-hours. With next-generation observatories on the horizon, this computational cost is set to become an insurmountable barrier to discovery.

### A Trusted Algorithm on New Hardware
Our work introduces a GPU-accelerated nested sampling algorithm that provides a direct path for the community to harness the power of parallel computing. Instead of inventing a new sampling method from scratch, we have carefully re-implemented the trusted 'acceptance-walk' sampling kernel—a workhorse of GW inference within `bilby` and `dynesty`—inside the JAX-based `blackjax-ns` framework. This framework, built upon the vectorized nested sampling concepts introduced in [Yallup et al. (2025a)](https://openreview.net/forum?id=ekbkMSuPo4), is specifically designed for GPU architectures.

Key technical adaptations were required to translate the sequential logic of the 'acceptance-walk' sampler to a massively parallel environment:
*   **Batched Processing:** Rather than replacing one "live point" at a time, our sampler replaces a large batch of points simultaneously, leveraging the GPU's thousands of cores.
*   **Parallel MCMC Walks:** The core of the sampler—a Differential Evolution MCMC walk—is parallelized, with each core in the batch independently seeking a new sample that satisfies the likelihood constraint.
*   **Architectural Modifications:** We modified the adaptive tuning of the MCMC walk length to operate at the batch level, preventing thread divergence and ensuring uniform workload across the GPU. We also derived a correction factor to account for the "saw-tooth" pattern in the number of live points that arises from batched updates, ensuring a fair, like-for-like comparison with CPU-based methods.

### Validated Performance and a New Baseline
By pairing our sampling kernel with a GPU-native waveform library, `ripple` ([10.1103/PhysRevD.110.064028](https://doi.org/10.1103/PhysRevD.110.064028)), we achieve dramatic performance gains. Our analyses of simulated binary black hole signals demonstrate:
*   **Exceptional Speedups:** We achieve typical wall-time speedups of 20-40x over a 16-core CPU implementation, translating to a direct cost reduction of 1.5-2.5x based on current cloud computing rates.
*   **Statistical Equivalence:** A rigorous 100-injection study confirms that our GPU implementation produces posteriors and evidence estimates that are statistically identical to the original CPU-based `bilby` framework.
*   **Dominance of Parallel Sampling:** We disentangled the sources of acceleration and found that the batched, inter-sample parallelism of the algorithm contributes more to the speedup than the intra-likelihood parallelization over frequency bins alone.

Crucially, this work establishes a foundational performance benchmark. By faithfully porting a community-standard algorithm, we isolate and quantify the performance gains attributable solely to the architectural shift from CPUs to GPUs. This provides a vital reference point against which future, novel parallel sampling algorithms can be rigorously assessed, allowing a clear distinction between algorithmic innovation and hardware-derived speed. Our validated tool empowers the community to tackle previously prohibitive analyses, paving the way for the next generation of gravitational-wave discovery.
<!-- END OF GENERATED POST -->

<img src="/assets/group/images/metha_prathaban.jpg" alt="Metha Prathaban" style="width: auto; height: 12vw;"><img src="/assets/group/images/david_yallup.jpg" alt="David Yallup" style="width: auto; height: 12vw;"><img src="https://www.kicc.cam.ac.uk/sites/default/files/styles/inline/public/images/profile/profilepicture-min_1.jpeg?itok=ccmz2RPK" alt="James Alvey" style="width: auto; height: 12vw;"><img src="/assets/group/images/ming_yang.jpg" alt="Ming Yang" style="width: auto; height: 12vw;"><img src="/assets/group/images/will_templeton.jpg" alt="Will Templeton" style="width: auto; height: 12vw;"><img src="/assets/group/images/will_handley.jpg" alt="Will Handley" style="width: auto; height: 12vw;">

Content generated by [gemini-2.5-pro](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/content/2025-09-04-2509.04336.txt).

Image generated by [imagen-4.0-generate-001](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/images/2025-09-04-2509.04336.txt).