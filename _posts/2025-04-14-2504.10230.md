---
layout: post
title:  "Extracting cosmological information from the abundance of galaxy
  clusters with simulation-based inference"
date:   2025-04-14
categories: papers
---
![AI generated image](/assets/images/posts/2025-04-14-2504.10230.png)

<!-- BEGINNING OF GENERATED POST -->
Our new paper, [2504.10230](https://arxiv.org/abs/2504.10230), introduces a powerful and efficient method for cosmological inference using one of the most established probes of the large-scale Universe: the abundance of galaxy clusters. Counting clusters as a function of their mass and redshift provides strong constraints on key cosmological parameters, including the matter density $\Omega_{\mathrm{m}}$ and the amplitude of matter clustering $\sigma_8$ ([1103.4829](https://arxiv.org/abs/1103.4829)). However, traditional analyses have always relied on constructing an explicit likelihood function—a mathematical object that describes the probability of observing the data given a set of model parameters. Developing, validating, and evaluating these likelihoods is often a formidable challenge, requiring significant effort and computational resources.

In this work, lead author [Íñigo Zubeldia](), along with Boris Bolliet, Anthony Challinor, and [Will Handley](https://willhandley.co.uk), pioneers an alternative path that bypasses these challenges by employing Simulation-Based Inference (SBI). SBI is a rapidly developing class of methods that flips the traditional paradigm on its head (see review [1911.01429](https://arxiv.org/abs/1911.01429)). Instead of defining an explicit likelihood, SBI learns the relationship between parameters and data directly from simulations. Since generating synthetic galaxy cluster catalogues is vastly simpler than writing a corresponding likelihood function, this approach promises to dramatically accelerate cosmological discovery.

### Rigorous Validation and a New Frontier
To prove the method's capability, we first validated our SBI pipeline in a highly demanding scenario: a simulated galaxy cluster survey mirroring the upcoming Simons Observatory ([1808.07445](https://arxiv.org/abs/1808.07445)). The results were exceptionally promising. Our SBI-based approach recovered cosmological parameters with posterior means that were within $0.2\sigma$ of those from a conventional, explicit likelihood analysis, and we constrained any potential biases to be smaller than $0.1\sigma$.

A key innovation of our work is the introduction of a procedure to assess the goodness-of-fit using only the same kind of synthetic catalogues used for training the SBI model. This demonstrates, for the first time, that a complete and robust cluster number count analysis can be performed without resorting to an explicit likelihood at any stage.

### From Simulation to Reality: Analyzing the *Planck* Catalogue
The ultimate test for any new methodology is its performance on real-world data. We applied our SBI framework to the publicly available *Planck* MMF3 cosmology sample, a cornerstone of the *Planck* Collaboration's 2015 cluster analysis ([1502.01597](https://arxiv.org/abs/1502.01597)). This marked the first-ever SBI-based number count analysis of a real galaxy cluster catalogue. The outcome was a resounding success: our method yielded cosmological constraints that agree with our own likelihood-based reanalysis to within $0.1\sigma$ for all parameters, confirming the robustness and real-world applicability of the likelihood-free approach.

### The Advantages of Going Likelihood-Free
This work opens a new, more efficient, and more flexible path forward for cluster cosmology. The SBI-based approach offers several transformative advantages over traditional methods:
*   **Reduced Development Time:** It sidesteps the months or even years of human effort required to develop, implement, and validate complex, multi-dimensional likelihood codes.
*   **Enhanced Accuracy and Flexibility:** Synthetic catalogues are exact realisations of the assumed model, ensuring accuracy across the entire parameter space where likelihood integral computations might falter. The method is also insensitive to model complexities like correlated or mass-dependent scatter, which pose significant challenges for likelihood evaluation.
*   **Computational Efficiency:** While training the inference network requires significant upfront computation, this process is trivially parallelisable. The resulting amortised posterior is extremely fast to evaluate, a stark contrast to the often-slow, serial nature of MCMC sampling with complex likelihoods.
*   **Future-Proofing:** It provides a straightforward framework for incorporating complex physical effects like sample variance from cluster clustering by using catalogues from full N-body simulations—a notoriously difficult task for standard likelihood-based approaches.

By demonstrating a robust, accurate, and efficient likelihood-free framework, we believe SBI is poised to become a key tool for cosmological analysis. It will significantly accelerate our ability to extract fundamental physics from the wealth of data provided by current and next-generation surveys like eROSITA, *Euclid*, and the Rubin Observatory.
<!-- END OF GENERATED POST -->

<img src="/assets/group/images/will_handley.jpg" alt="Will Handley" style="width: auto; height: 25vw;">

Content generated by [gemini-2.5-pro](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/content/2025-04-14-2504.10230.txt).

Image generated by [imagen-3.0-generate-002](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/images/2025-04-14-2504.10230.txt).