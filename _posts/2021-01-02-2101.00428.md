---
layout: post
title:  "Convergent Bayesian Global Fits of 4D Composite Higgs Models"
date:   2021-01-02
categories: papers
---
![AI generated image](/assets/images/posts/2021-01-02-2101.00428.png)

<!-- BEGINNING OF GENERATED POST -->
In our latest work, "[Convergent Bayesian Global Fits of 4D Composite Higgs Models](https://arxiv.org/abs/2101.00428)", lead author [Ethan Carragher](mailto:ethan.carragher@adelaide.edu.au) and collaborators, including [Will Handley](https://willhandley.co.uk), tackle one of the most pressing puzzles in particle physics: the Higgs mass naturalness problem. While the Standard Model is remarkably successful, it requires an uncomfortable level of fine-tuning to explain the observed Higgs mass. Composite Higgs Models (CHMs) provide an elegant solution by positing that the Higgs is not a fundamental particle, but a composite pseudo-Nambu-Goldstone boson arising from a new strong dynamics at the TeV scale.

This study moves beyond previous analyses by performing the first-ever *convergent* global fits of realistic CHMs. We investigate three prominent Minimal 4D Composite Higgs Models (M4DCHMs) built on the $SO(5) \rightarrow SO(4)$ symmetry breaking pattern, as detailed in foundational work like that of Agashe, Contino, and Pomarol ([hep-ph/0412089](https://arxiv.org/abs/hep-ph/0412089)). The immense complexity and high dimensionality of these models' parameter spaces (up to 22 dimensions) have traditionally hindered exhaustive exploration. Our approach overcomes this challenge by deploying a rigorous Bayesian framework powered by `PolyChord` ([1502.01856](https://arxiv.org/abs/1502.01856)), our group's advanced nested sampling algorithm. This allows us to map the full posterior probability distribution, simultaneously weighing experimental evidence against model naturalness.

### A New Perspective on Fine-Tuning
A key innovation of this work is a new method for quantifying fine-tuning. Instead of relying on traditional sensitivity measures, we employ the Kullback-Leibler (KL) divergence. This information-theoretic quantity measures the information gain from the prior to the posterior, providing a principled and holistic assessment of how much the experimental data must 'tune' the model's parameters away from their natural state. This allows for a more robust comparison of the intrinsic naturalness of different theoretical frameworks.

### Key Findings and Testable Predictions
Our comprehensive analysis constrains the viable parameter space of these models and yields sharp, testable predictions for future collider experiments.

*   **Model Comparison:** The Bayesian evidence decisively favors the M4DCHM$^{5-5-5}$ model, suggesting it provides a more natural fit to the collective data. However, we stress that this conclusion is sensitive to the choice of priors, and a fully conclusive comparison would require further analysis of this dependence.

*   **Probing the Parameter Space:** We discovered that the likelihood is confined to thin hypersurfaces or 'sheets' within the high-dimensional parameter space. The Bayesian Model Dimensionality (BMD) reveals that these viable regions have an effective dimensionality of only ~7-12, a significant reduction from the full ~18+ dimensions of the models.

*   **Collider Phenomenology:** The fits place stringent constraints on the properties of new particles predicted by these models:
    *   The lightest new fermionic resonances are robustly excluded below approximately 1.1 TeV.
    *   Two of the models (M4DCHM$^{14-14-10}$ and M4DCHM$^{14-1-10}$) predict a notable suppression of the gluon-fusion Higgs production cross-section decaying to two photons ($gg \rightarrow H \rightarrow \gamma\gamma$), to between 80% and 90% of the Standard Model value. This is already in slight tension with current LHC data and presents a powerful test for the high-luminosity runs, which could potentially rule out these scenarios. This finding echoes challenges noted in earlier studies, for example in [1210.7114](https://arxiv.org/abs/1210.7114).
    *   The exotic fermion decays $Q_{5/3} \rightarrow tW^{+}$ and $Q_{4/3} \rightarrow \bar{b}W^{+}$ emerge as particularly clean and promising channels for discovering or constraining these models in future searches.

Ultimately, this research provides the most rigorous statistical exploration of M4DCHMs to date. By combining a robust Bayesian methodology with powerful computational tools, we have refined our understanding of these compelling alternatives to the Standard Model, identified their most natural configurations, and produced concrete phenomenological targets for the next generation of particle physics experiments.
<!-- END OF GENERATED POST -->

<img src="/assets/group/images/will_handley.jpg" alt="Will Handley" style="width: auto; height: 25vw;">

Content generated by [gemini-2.5-pro](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/content/2021-01-02-2101.00428.txt).

Image generated by [imagen-3.0-generate-002](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/images/2021-01-02-2101.00428.txt).