{% raw %}

Title: Create a Markdown Blog Post Integrating Research Details and a Featured Paper
====================================================================================

This task involves generating a Markdown file (ready for a GitHub-served Jekyll site) that integrates our research details with a featured research paper. The output must follow the exact format and conventions described below.

====================================================================================
Output Format (Markdown):
------------------------------------------------------------------------------------
---
layout: post
title:  "Calibrating Bayesian Tension Statistics using Neural Ratio Estimation"
date:   2024-07-22
categories: papers
---
![AI generated image](/assets/images/posts/2024-07-22-2407.15478.png)

<!-- BEGINNING OF GENERATED POST -->
<!-- END OF GENERATED POST -->

<img src="/assets/group/images/harry_bevins.jpg" alt="Harry Bevins" style="width: auto; height: 20vw;"><img src="/assets/group/images/will_handley.jpg" alt="Will Handley" style="width: auto; height: 20vw;"><img src="/assets/group/images/thomas_gessey-jones.jpg" alt="Thomas Gessey-Jones" style="width: auto; height: 20vw;">

Content generated by [gemini-1.5-pro](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/content/2024-07-22-2407.15478.txt).

Image generated by [imagen-3.0-generate-002](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/images/2024-07-22-2407.15478.txt).

------------------------------------------------------------------------------------
====================================================================================

Please adhere strictly to the following instructions:

====================================================================================
Section 1: Content Creation Instructions
====================================================================================

1. **Generate the Page Body:**
   - Write a well-composed, engaging narrative that is suitable for a scholarly audience interested in advanced AI and astrophysics.
   - Ensure the narrative is original and reflective of the tone and style and content in the "Homepage Content" block (provided below), but do not reuse its content.
   - Use bullet points, subheadings, or other formatting to enhance readability.

2. **Highlight Key Research Details:**
   - Emphasize the contributions and impact of the paper, focusing on its methodology, significance, and context within current research.
   - Specifically highlight the lead author ({'name': 'Harry T. J. Bevins'}). When referencing any author, use Markdown links from the Author Information block (choose academic or GitHub links over social media).

3. **Integrate Data from Multiple Sources:**
   - Seamlessly weave information from the following:
     - **Paper Metadata (YAML):** Essential details including the title and authors.
     - **Paper Source (TeX):** Technical content from the paper.
     - **Bibliographic Information (bbl):** Extract bibliographic references.
     - **Author Information (YAML):** Profile details for constructing Markdown links.
   - Merge insights from the Paper Metadata, TeX source, Bibliographic Information, and Author Information blocks into a coherent narrativeâ€”do not treat these as separate or isolated pieces.
   - Insert the generated narrative between the HTML comments:
     <!-- BEGINNING OF GENERATED POST --> and <!-- END OF GENERATED POST -->

4. **Generate Bibliographic References:**
   - Review the Bibliographic Information block carefully.
   - For each reference that includes a DOI or arXiv identifier:
     - For DOIs, generate a link formatted as:
       [10.1234/xyz](https://doi.org/10.1234/xyz)
     - For arXiv entries, generate a link formatted as:
       [2103.12345](https://arxiv.org/abs/2103.12345)
    - **Important:** Do not use any LaTeX citation commands (e.g., `\cite{...}`). Every reference must be rendered directly as a Markdown link. For example, instead of `\cite{mycitation}`, output `[mycitation](https://doi.org/mycitation)`
        - **Incorrect:** `\cite{10.1234/xyz}`  
        - **Correct:** `[10.1234/xyz](https://doi.org/10.1234/xyz)`
   - Ensure that at least three (3) of the most relevant references are naturally integrated into the narrative.
   - Ensure that the link to the Featured paper [2407.15478](https://arxiv.org/abs/2407.15478) is included in the first sentence.

5. **Final Formatting Requirements:**
   - The output must be plain Markdown; do not wrap it in Markdown code fences.
   - Preserve the YAML front matter exactly as provided.

====================================================================================
Section 2: Provided Data for Integration
====================================================================================

1. **Homepage Content (Tone and Style Reference):**
```markdown
---
layout: home
---

![AI generated image](/assets/images/index.png)

<!-- START OF WEBSITE SUMMARY -->
The Handley Research Group is dedicated to advancing our understanding of the Universe through the development and application of cutting-edge artificial intelligence and Bayesian statistical inference methods. Our research spans a wide range of cosmological topics, from the very first moments of the Universe to the nature of dark matter and dark energy, with a particular focus on analyzing complex datasets from next-generation surveys.

## Research Focus

Our core research revolves around developing innovative methodologies for analyzing large-scale cosmological datasets. We specialize in Simulation-Based Inference (SBI), a powerful technique that leverages our ability to simulate realistic universes to perform robust parameter inference and model comparison, even when likelihood functions are intractable ([LSBI framework](https://arxiv.org/abs/2501.03921)).  This focus allows us to tackle complex astrophysical and instrumental systematics that are challenging to model analytically ([Foreground map errors](https://arxiv.org/abs/2211.10448)).

A key aspect of our work is the development of next-generation SBI tools ([Gradient-guided Nested Sampling](https://arxiv.org/abs/2312.03911)), particularly those based on neural ratio estimation. These methods offer significant advantages in efficiency and scalability for high-dimensional inference problems ([NRE-based SBI](https://arxiv.org/abs/2207.11457)).  We are also pioneering the application of these methods to the analysis of Cosmic Microwave Background ([CMB](https://arxiv.org/abs/1908.00906)) data, Baryon Acoustic Oscillations ([BAO](https://arxiv.org/abs/1701.08165)) from surveys like DESI and 4MOST, and gravitational wave observations.

Our AI initiatives extend beyond standard density estimation to encompass a broader range of machine learning techniques, such as:

* **Emulator Development:** We develop fast and accurate emulators of complex astrophysical signals ([globalemu](https://arxiv.org/abs/2104.04336)) for efficient parameter exploration and model comparison ([Neural network emulators](https://arxiv.org/abs/2503.13263)).
* **Bayesian Neural Networks:** We explore the full posterior distribution of Bayesian neural networks for improved generalization and interpretability ([BNN marginalisation](https://arxiv.org/abs/2205.11151)).
* **Automated Model Building:**  We are developing novel techniques to automate the process of building and testing theoretical cosmological models using a combination of symbolic computation and machine learning ([Automated model building](https://arxiv.org/abs/2006.03581)).

Additionally, we are active in the development and application of advanced sampling methods like nested sampling ([Nested sampling review](https://arxiv.org/abs/2205.15570)), including dynamic nested sampling ([Dynamic nested sampling](https://arxiv.org/abs/1704.03459)) and its acceleration through techniques like posterior repartitioning ([Accelerated nested sampling](https://arxiv.org/abs/2411.17663)).

## Highlight Achievements

Our group has a strong publication record in high-impact journals and on the arXiv preprint server. Some key highlights include:

* Development of novel AI-driven methods for analyzing the 21-cm signal from the Cosmic Dawn ([21-cm analysis](https://arxiv.org/abs/2201.11531)).
* Contributing to the Planck Collaboration's analysis of CMB data ([Planck 2018](https://arxiv.org/abs/1807.06205)).
* Development of the PolyChord nested sampling software ([PolyChord](https://arxiv.org/abs/1506.00171)), which is now widely used in cosmological analyses.
* Contributions to the GAMBIT global fitting framework ([GAMBIT CosmoBit](https://arxiv.org/abs/2009.03286)).
* Applying SBI to constrain dark matter models ([Dirac Dark Matter EFTs](https://arxiv.org/abs/2106.02056)).

## Future Directions

We are committed to pushing the boundaries of cosmological analysis through our ongoing and future projects, including:

* Applying SBI to test extensions of General Relativity ([Modified Gravity](https://arxiv.org/abs/2006.03581)).
* Developing AI-driven tools for efficient and robust calibration of cosmological experiments ([Calibration for astrophysical experimentation](https://arxiv.org/abs/2307.00099)).
* Exploring the use of transformers and large language models for automating the process of cosmological model building.
* Applying our expertise to the analysis of data from next-generation surveys like Euclid, the Vera Rubin Observatory, and the Square Kilometre Array.  This will allow us to probe the nature of dark energy with increased precision ([Dynamical Dark Energy](https://arxiv.org/abs/2503.08658)), search for parity violation in the large-scale structure ([Parity Violation](https://arxiv.org/abs/2410.16030)), and explore a variety of other fundamental questions.



<!-- END OF WEBSITE SUMMARY -->

Content generated by [gemini-1.5-pro](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/content/index.txt).

Image generated by [imagen-3.0-generate-002](https://deepmind.google/technologies/gemini/) using [this prompt](/prompts/images/index.txt).

```

2. **Paper Metadata:**
```yaml
!!python/object/new:feedparser.util.FeedParserDict
dictitems:
  id: http://arxiv.org/abs/2407.15478v1
  guidislink: true
  link: http://arxiv.org/abs/2407.15478v1
  updated: '2024-07-22T08:46:11Z'
  updated_parsed: !!python/object/apply:time.struct_time
  - !!python/tuple
    - 2024
    - 7
    - 22
    - 8
    - 46
    - 11
    - 0
    - 204
    - 0
  - tm_zone: null
    tm_gmtoff: null
  published: '2024-07-22T08:46:11Z'
  published_parsed: !!python/object/apply:time.struct_time
  - !!python/tuple
    - 2024
    - 7
    - 22
    - 8
    - 46
    - 11
    - 0
    - 204
    - 0
  - tm_zone: null
    tm_gmtoff: null
  title: Calibrating Bayesian Tension Statistics using Neural Ratio Estimation
  title_detail: !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      type: text/plain
      language: null
      base: ''
      value: Calibrating Bayesian Tension Statistics using Neural Ratio Estimation
  summary: 'When fits of the same physical model to two different datasets disagree,
    we

    call this tension. Several apparent tensions in cosmology have occupied

    researchers in recent years, and a number of different metrics have been

    proposed to quantify tension. Many of these metrics suffer from limiting

    assumptions, and correctly calibrating these is essential if we want to

    successfully determine whether discrepancies are significant. A commonly used

    metric of tension is the evidence ratio R. The statistic has been widely

    adopted by the community as a Bayesian way of quantifying tensions, however, it

    has a non-trivial dependence on the prior that is not always accounted for

    properly. We show that this can be calibrated out effectively with Neural Ratio

    Estimation. We demonstrate our proposed calibration technique with an analytic

    example, a toy example inspired by 21-cm cosmology, and with observations of

    the Baryon Acoustic Oscillations from the Dark Energy Spectroscopic

    Instrument~(DESI) and the Sloan Digital Sky Survey~(SDSS). We find no

    significant tension between DESI and SDSS.'
  summary_detail: !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      type: text/plain
      language: null
      base: ''
      value: 'When fits of the same physical model to two different datasets disagree,
        we

        call this tension. Several apparent tensions in cosmology have occupied

        researchers in recent years, and a number of different metrics have been

        proposed to quantify tension. Many of these metrics suffer from limiting

        assumptions, and correctly calibrating these is essential if we want to

        successfully determine whether discrepancies are significant. A commonly used

        metric of tension is the evidence ratio R. The statistic has been widely

        adopted by the community as a Bayesian way of quantifying tensions, however,
        it

        has a non-trivial dependence on the prior that is not always accounted for

        properly. We show that this can be calibrated out effectively with Neural
        Ratio

        Estimation. We demonstrate our proposed calibration technique with an analytic

        example, a toy example inspired by 21-cm cosmology, and with observations
        of

        the Baryon Acoustic Oscillations from the Dark Energy Spectroscopic

        Instrument~(DESI) and the Sloan Digital Sky Survey~(SDSS). We find no

        significant tension between DESI and SDSS.'
  authors:
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      name: Harry T. J. Bevins
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      name: William J. Handley
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      name: Thomas Gessey-Jones
  author_detail: !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      name: Thomas Gessey-Jones
  author: Thomas Gessey-Jones
  links:
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      href: http://arxiv.org/abs/2407.15478v1
      rel: alternate
      type: text/html
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      title: pdf
      href: http://arxiv.org/pdf/2407.15478v1
      rel: related
      type: application/pdf
  arxiv_primary_category:
    term: astro-ph.CO
    scheme: http://arxiv.org/schemas/atom
  tags:
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      term: astro-ph.CO
      scheme: http://arxiv.org/schemas/atom
      label: null
  - !!python/object/new:feedparser.util.FeedParserDict
    dictitems:
      term: astro-ph.IM
      scheme: http://arxiv.org/schemas/atom
      label: null

```

3. **Paper Source (TeX):**
```tex
%% ****** Start of file template.aps ****** %
%%
%%
%%   This file is part of the APS files in the REVTeX 4 distribution.
%%   Version 4.0 of REVTeX, August 2001
%%
%%
%%   Copyright (c) 2001 The American Physical Society.
%%
%%   See the REVTeX 4 README file for restrictions and more information.
%%
%
% For Phys. Rev. appearance, change preprint to twocolumn.
% Choose pra, prb, prc, prd, pre, prl, prstab, or rmp for journal
%  Add 'draft' option to mark overfull boxes with black boxes
%
%
% To compile: latex prl.tex ; dvips prl.dvi -o prl.ps ; ps2pdf prl.ps
%
\documentclass[aps, prd,twocolumn,superscriptaddress, groupedaddress]{revtex4}
\usepackage{graphicx}  % needed for figures
\usepackage{dcolumn}   % needed for some tables
\usepackage{bm}        % for math
\usepackage{amssymb}   % for math
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{subcaption}

\DeclareMathOperator*{\argmax}{argmax}

\crefformat{figure}{Fig.~#2#1#3}
\crefformat{equation}{equation~(#2#1#3)}
\crefformat{section}{section~#2#1#3}
\crefformat{table}{Tab.~#2#1#3}
\crefformat{appendix}{appendix~#2#1#3}
\crefmultiformat{figure}{Figs.~#2#1#3}{~and~#2#1#3}%
    {,~#2#1#3}{,~#2#1#3}
\crefrangeformat{figure}{Figs.~(#3#1#4--#5#2#6)}

\newcommand{\comment}[1]{}

\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{newtxtext,newtxmath}

\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\mynote}[1]{\todo[size=\small,inline,color=green!40]{#1}}


\begin{document}
\title{Calibrating Bayesian Tension Statistics using Neural Ratio Estimators}
\author{Harry T. J. Bevins$^{1, 2}$,
\thanks{htjb2@cam.ac.uk}
William J. Handley$^{1, 2}$,
Thomas Gessey-Jones}

\address{Astrophysics Group, Cavendish Laboratory, Cambridge, CB3 0HE, UK}
\address{Kavli Institute for Cosmology, Cambridge, CB3 0HA, UK}

\begin{abstract}

When fits of the same physical model to two different datasets disagree, we call this tension. Several apparent tensions in cosmology have occupied researchers in recent years, and a number of different metrics have been proposed to quantify tension. Many of these metrics suffer from limiting assumptions, and correctly calibrating these is essential if we want to successfully determine whether discrepancies are significant.
A commonly used metric of tension is the evidence ratio $R$. The statistic has been widely adopted by the community as a Bayesian way of quantifying tensions, however, it has a non-trivial dependence on the prior that is not always accounted for properly.
We show that this can be calibrated out effectively with Neural Ratio Estimation.
We demonstrate our proposed calibration technique with an analytic example, a toy example inspired by 21-cm cosmology, and with observations of the Baryon Acoustic Oscillations from the Dark Energy Spectroscopic Instrument~(DESI) and the Sloan Digital Sky Survey~(SDSS). We find no significant tension between DESI and SDSS. 
\end{abstract}

\maketitle

\section{Introduction}

Independently confirming conclusions about the nature of our Universe from one experiment with another is crucial to the advance of knowledge. When the inference from two different experiments disagree with each other, we call this tension.
Tension between different datasets raises questions about the need for new physics and better descriptions of our instruments and systematics. The $H_0$ and $\sigma_8$ tensions \citep[e.g.][]{knox2020HubbleHunters, Efstathiou2020LockdownH0, Amon2022s8, Preston2023s8, Abbott2023DESKIDS}  are the most commonly encountered examples in cosmology, but other examples include observations of the 21-cm signal from cosmic dawn \citep{Singh_SARAS3_2022}, tensions in the amplitude of the matter power spectrum \citep{Battye_tensions_2015} and tension in estimates of the curvature of the Universe \cite{Handley2019Curvature}. A historical example of tension is in the measurement of the matter density $\Omega_m$ \cite{Peebles1984OmegaM, Krauss1995OmegaM, Ostriker1995OmegaM, Efstathiou1990OmegaM} which was resolved by the discovery of the accelerating universe \cite{Riess1998Accelerating}. A detailed review of cosmological tensions can be found in \cite{Abdalla2022TensionReview}. 

Many different measures of tension have been proposed and are widely used in cosmological studies. Examples include Bayesian Suspiciousness \cite{Handley_tensions_2019}, estimators of the probability of observed parameter differences \cite{Raveri2020parameterDifference, Raveri2021ParameterDiff}, Goodness of fit degradation \cite{Raveri2019GoFDegredation} and Eigentension \cite{Park2020Eigentension}. These tension statistics are summarised and reviewed in \cite{Charnock_2017, Lemos2021DESTensions} and \cite{Saraivanov2024Metrics}. It is common practice to rephrase these tension metrics in $\sigma$ units of tension,  corresponding to probabilities on a one dimensional normal distribution. When expressed in this way, one would expect that the various tension metrics predict the same level of tension or concordance between different datasets. However, this is often not the case due to the various assumptions that are made when defining the statistics.
To tackle this issue, we can try to define tension metrics that do not make these assumptions, however, the tension statistics often lose some of their interpretability when we do this. Instead, we try to calibrate out these assumptions in sensible ways. Calibration of tension statistics is an important and often overlooked step that needs to be taken to correctly interrogate the tension between different datasets.

A commonly used metric of tension is $R$ corresponding to the ratio of a joint evidence and the product of individual evidences for two different datasets under a common model. The $R$ statistic was first proposed in \citep{Marshall_2006} and has been used to quantify tension in a number of cosmological studies \citep[e.g.][]{Trotta_2008, Seehars_2016}. $R$ has also been used to perform model comparison in some works, although the authors of \cite{Cortes2024Tension} showed that this approach to model comparison is incomplete. 

The ratio $R$ suffers from a non-trivial dependence on the prior that is not always accounted for properly \citep{Handley_tensions_2019}. In \cite{Handley_tensions_2019} the authors showed that as one decreases the prior width on the common parameters in the model of the two datasets, then the tension between the datasets should increase and $R$ should decrease. Intuitively, one can see that it is more satisfying if the two experiments favour parameters that are close together given a wide prior in comparison to a narrow prior. However, what constitutes `narrow' and `wide' is problem specific and subjective, making the interpretation of $R$ difficult. We would like to calibrate out the prior dependence.

The authors of \cite{Handley_tensions_2019} propose an alternative statistic that is closely related to $R$ called the Suspiciousness $S$ which is insensitive to the prior provided the change in prior do not impact the posterior significantly. In \cite{Cuceu2019BAO} the authors convert $S$ into $\sigma$s of tension, however, this requires an estimate of the number of constrained dimensions $d$ in the joint analysis. To estimate $d$ they use the Bayesian (sometimes referred to as Gaussian) Model Dimensionality, however, this is a poor estimator of $d$ if the posterior is significantly non-Gaussian, as is often the case in cosmology.


In \cite{Lemos2021DESTensions} the authors demonstrate that simulations can be used to calibrate tension metrics with the Planck data and Dark Energy Survey~(DES) data. They proposed taking a fiducial set of parameters, such as the maximum posterior point for Planck, shifting these parameter values by some posterior-informed step sizes to induce a known degree of tension, simulate the now in tension DES observations and calculate the value of ones chosen tension metric between the real Planck data and the simulation. 
To do this, however, one often has to run expensive sampling algorithms on the simulated data to calculate tension statistics such as $R$ and $S$.

We propose calibrating the prior dependence of $R$ using neural ratio estimation~(NRE) \citep[e.g.][]{Cranmer202SBI, Miller2021TMNRE, Cole2022TMNRE}.  
NREs are classifiers, with interpretable outputs, that determine whether two quantities are drawn from independent distributions or a joint distribution. 
We show that the output of an NRE trained on simulations of two experiments observables can be interpreted as $R$ and that an appropriately trained NRE can be used to calibrate for the prior dependence of the dimensionless $R$ statistic. Since $R$ requires the calculation of three Bayesian evidences, it is an expensive statistic to evaluate using traditional methods like nested sampling. We show that $R$ can be accessed with a significantly smaller computational overhead using cutting edge machine learning tools.
We call our NRE setup the \textsc{tensionnet}.

In \cref{sec:bayes} we summarise Bayesian inference and give more details about $R$. In \cref{sec:interpretation} we discuss the interpretation of $R$ and follow this with a discussion on NREs in \cref{sec:nres}. We discuss calibrating $R$ with NREs in \cref{sec:calibration_r}. We then test our method on toy examples with known in concordance $R$ distributions in \cref{sec:validation}. We then apply the \textsc{tensionnet} to a toy example inspired by 21-cm cosmology and to assess the tension between Baryon Acoustic Oscillations~(BAO) observations from the Dark Energy Spectroscopic Instrument~(DESI) and the Sloan Digital Sky Survey~(SDSS), in \cref{sec:cosmological_examples}. We consider some limitations of our method in \cref{sec:limitations} and conclude in \cref{sec:conclusions}.

The code used in this paper is publicly available at \url{https://github.com/htjb/tension-networks}.

\section{Bayesian Inference and Tension Statistics}
\label{sec:bayes}

In Bayesian inference we are interested in modelling data $D$ with a model $M$ containing parameters $\theta$ to recover both the probability of the data given the model $\mathcal{Z} = P(D|M)$ or evidence and the probability of a given $\theta$ given the data and model $P(\theta) = P(\theta|D, M)$ or posterior. To do this we draw samples from a prior $\pi(\theta)=P(\theta|M)$ which encodes our prior knowledge of the parameters and evaluate a likelihood which is our postulated probability of the data given a set of parameters and model $L(\theta) = P(D|\theta, M)$. We relate these quantities using Bayes theorem
\begin{equation}
    P(\theta|D, M) = \frac{P(D|\theta, M)P(\theta|M)}{P(D|M)} = \frac{\mathcal{L}(\theta) \pi(\theta)}{\mathcal{Z}},
    \label{eq:bayes}
\end{equation}
where $\mathcal{Z}$ is given by
\begin{equation}
    \mathcal{Z} = \int \mathcal{L}(\theta) \pi(\theta) d\theta.
\end{equation}
An efficient and accurate way to recover both the evidence and the posterior is with nested sampling \citep{skilling_ns_2006, Ashton_NS_2022} although other methods exist \citep[e.g.][]{Trotta_2007, Heavens_2017, Srinivasan2024floZ, emcee, Polanska2023harmonicmean}.

The tension $R$ between two datasets, indicated by the subscripts $A$ and $B$, is
\begin{equation}
    R = \frac{\mathcal{Z}_{A,B}}{\mathcal{Z}_A \mathcal{Z}_B} = \frac{P(D_A, D_B|M)}{P(D_A|M)P(D_B|M)} = \frac{P(D_A, D_B)}{P(D_A)P(D_B)},
    \label{eq:R_statistic}
\end{equation}
where we have dropped the dependence on $M$ in the last expression for conciseness.
$R$ is prior dependent and this can be seen by noting that
\begin{equation}
\begin{aligned}
    R &= \frac{\mathcal{Z}_{A,B}}{\mathcal{Z}_A \mathcal{Z}_B} = \frac{1}{\mathcal{Z}_A \mathcal{Z}_B} \int \mathcal{L}_A \mathcal{L}_B \pi d\theta \\ & = \int \frac{\mathcal{L}_A \pi}{\mathcal{Z}_A} \frac{\mathcal{L}_B \pi}{\mathcal{Z}_B} \frac{1}{\pi} d\theta  = \int \frac{P_A P_B}{\pi} d\theta \\ & = \bigg\langle \frac{P_B}{\pi} \bigg\rangle_{P_A} =  \bigg\langle \frac{P_A}{\pi} \bigg\rangle_{P_B}
\end{aligned}
    \label{eq:prior_dependence}
\end{equation} 
where we have assumed the data sets are independent, and the angled brackets represent averages over the distributions $P_A$ and $P_B$ \citep{Handley_tensions_2019}. For a uniform prior, $\pi = 1/V$ where $V$ is the volume, one can see from \cref{eq:prior_dependence} that if the prior is made smaller than $R$ being proportional to $V$ also decreases. This logic generalises to more complicated priors.

\section{Interpreting $R$}
\label{sec:interpretation}

$R$ has the attractive properties of being dimensionally consistent, parameterisation invariant and symmetric \cite{Handley_tensions_2019}. It is typically interpreted with respect to a value of 1 with $R \ll 1$ corresponding to inconsistent datasets and $R \gg 1$ to consistent data. However, this interpretation does not tell us the degree to which our datasets are in tension given the prior and model choice. To try and quantify the tension between observations from the Dark Energy Survey and Planck, the authors of \cite{DES_Y1} interpreted $R$ on a Jefferys' scale\citep{jeffreys1983theory}. The Jefferys' scale is, however, somewhat arbitrary.

In \cite{Handley_tensions_2019} the authors showed that
\begin{equation}
    R = \frac{\mathcal{Z}_{A,B}}{\mathcal{Z}_A \mathcal{Z}_B} = \frac{P(D_A, D_B)}{P(D_A)P(D_B)} =\frac{P(D_A|D_B)}{P(D_A)} = \frac{P(D_B|D_A)}{P(D_B)},
\end{equation}
implying then one can interpret $R$, if it is greater than $1$, as a fractional increase in confidence in dataset $A$ given knowledge of dataset $B$ over $A$ alone (or vice versa). If $R \ll 1$ then the authors suggest we should be concerned about our model or the datasets.

When interpreting $R$ one has to keep in mind the impact which the prior has on its value. Reducing the width of the prior will increase the apparent tension between the datasets by reducing the value of $R$. The authors of \cite{Handley_tensions_2019} suggest repeating our analysis with sensible modifications to the prior distribution to determine how stable the value of $R$ is and consequently our conclusions regarding the tension between different datasets.

Given a choice of prior and model, there is a distribution of possible in concordance $R$ values that could be observed between two different experiments. Low signal-to-noise observations of the same signal by the two experiments will have lower typical values of $R$ in contrast to high signal-to-noise observations. This distribution can be used to translate between $R$ and $N\sigma$ estimates of tension, removing the prior dependence from the statistic and allowing for comparison with other tension metrics. The difficulty, however, is in accessing this distribution, which requires the evaluation of individual and joint evidences for a large sample of simulations, making it computationally expense and often intractable. In this paper, we propose calibrating the prior dependence of $R$ using simulations and NREs to quickly evaluate the in concordance $R$ distribution.

\section{Neural Ratio Estimation}
\label{sec:nres}

\begin{figure*}
    \centering
    \begin{tikzpicture}[rednode/.style={circle, draw=red!60, fill=red!5, very thick, minimum size=5mm},
                bluenode/.style={circle, draw=blue!60, fill=blue!5, very thick, minimum size=5mm},
                greennode/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=5mm},
                node distance=0.2cm and 1.7cm,
                remember picture]
        \node (0) {};
        
        \node[rednode, above=of 0, text width=0.5cm, align=center](layer1_center1) {};
        \node[rednode, below=of layer1_center1, text width=0.5cm, align=center](layer1_center2) {};
        \node[rednode, above=of layer1_center1, text width=0.5cm, align=center](layer1_top2) {};
        \node[rednode, below=of layer1_center2, text width=0.5cm, align=center](layer1_bottom1) {};
    
        \node[rednode, left=of layer1_top2, text width=0.5cm, align=center](hl1) {};
        \node[rednode, left=of layer1_center1, text width=0.5cm, align=center](hl2) {};
        \node[rednode, left=of layer1_center2, text width=0.5cm, align=center](hl3) {};
        \node[rednode, left=of layer1_bottom1, text width=0.5cm, align=center](hl4) {};
        
        \node[bluenode, below left=of hl1, text width=0.5cm, align=center, yshift=0.5cm](input_1) {$D_A$};
        \node[above=of input_1]{\Huge $\vdots$};
        \node[below=of input_1]{\Huge $\vdots$};
        \node[bluenode, below=of input_1, text width=0.5cm, align=center, yshift=-1cm](input_2) {$D_B$};
        \node[above=of input_2]{\Huge $\vdots$};
        \node[below=of input_2]{\Huge $\vdots$};

        \node[greennode, right=of layer1_center1, text width=0.7cm, align=center, yshift=-0.65cm](output_1) {$\log R$};
        \node[draw, rectangle, right=of output_1, text width=2cm, align=center, xshift=-1cm](output_2) {$p = S_\sigma(\log R)$};

        \node[draw, rectangle, below=of output_1, text width=7cm, align=center,
        xshift=2cm](loss) {
        Loss Function:
        \begin{equation*}
        l = \frac{1}{N}\bigg[ \sum_{i}^N y_i \log (p_i) + (1-y_i)\log (1 - p_i)\bigg]
        \end{equation*}};

        \node[draw, rectangle, above=of layer1_top2, text width=7cm, align=center, xshift=1cm](title){
        Neural Ratio Estimation of $\log R = \log \frac{P(D_A, D_B)}{P(D_A)P(D_B)}$
        };

        

        \draw[->, dashed](output_1.east) -- (output_2.west);
        \draw[->](input_1.east) -- (hl1.west);
        \draw[->](input_1.east) -- (hl2.west);
        \draw[->](input_1.east) -- (hl3.west);
        \draw[->](input_1.east) -- (hl4.west);
        
        \draw[->](input_2.east) -- (hl1.west);
        \draw[->](input_2.east) -- (hl2.west);
        \draw[->](input_2.east) -- (hl3.west);
        \draw[->](input_2.east) -- (hl4.west);
        
        
        \draw[->](hl1.east) -- (layer1_center1.west);
        \draw[->](hl2.east) -- (layer1_center1.west);
        \draw[->](hl3.east) -- (layer1_center1.west);
        \draw[->](hl4.east) -- (layer1_center1.west);
        
        \draw[->](hl1.east) -- (layer1_center2.west);
        \draw[->](hl2.east) -- (layer1_center2.west);
        \draw[->](hl3.east) -- (layer1_center2.west);
        \draw[->](hl4.east) -- (layer1_center2.west);
        
        \draw[->](hl1.east) -- (layer1_top2.west);
        \draw[->](hl2.east) -- (layer1_top2.west);
        \draw[->](hl3.east) -- (layer1_top2.west);
        \draw[->](hl4.east) -- (layer1_top2.west);
        
        \draw[->](hl1.east) -- (layer1_bottom1.west);
        \draw[->](hl2.east) -- (layer1_bottom1.west);
        \draw[->](hl3.east) -- (layer1_bottom1.west);
        \draw[->](hl4.east) -- (layer1_bottom1.west);
        
        \draw[->](layer1_center1.east) -- (output_1.west);
        \draw[->](layer1_center2.east) -- (output_1.west);
        \draw[->](layer1_top2.east) -- (output_1.west);
        \draw[->](layer1_bottom1) -- (output_1.west);

    \end{tikzpicture}
    \caption{A schematic of the neural ratio estimator~(NRE) used in this work, which we refer to as a \textsc{tensionnet}. The NRE is trained on matched and mismatched pairs of simulated observations from two different experiments $A$ and $B$ and outputs an estimate of the tension statistic $R$. The network is trained using the binary cross entropy loss function.}
    \label{fig:tension_network}
\end{figure*}

Neural Ratio Estimators~(NRE) are neural network classifiers that  are trained to return the probability that two inputs have been drawn from a joint distribution relative to the probability that they have been drawn from independent distributions. For training data that includes an equal number of examples of two inputs $A$ and $B$ drawn from their independent distributions and their joint distribution, the output of a neural ratio estimator tends towards
\begin{equation}
    \log r = \log \frac{P(A, B)}{P(A)P(B)}.
\end{equation}

To prove this, we begin by defining the network output as $f(A, B)$. During training, we give it examples drawn from the joint distribution $P(A, B)$ with probability $P_{\rm J}$ and drawn from $P(A)P(B)$ with probability $(1 - P_{\rm J})$. NREs are trained with a binary cross entropy loss function that is defined as
\begin{equation}
     l = \frac{1}{N}\bigg[ \sum_{i}^N y_i \log (\tilde{f}(A, B)) + (1-y_i)\log (1 - \tilde{f}(A, B))\bigg],
\end{equation}
where 
\begin{equation}
    \tilde{f}(A, B) \equiv S_\sigma(f(A, B)) = \frac{e^{f(A, B)}}{1 + e^{f(A, B)}},
\end{equation}
and where $y_{\rm i}$ is 1 for samples drawn from the joint and 0 for independent samples. $S_\sigma$ is the sigmoid activation function and scales the output of the network between 0 and 1.

In the limit of a large number of training samples, we can take the continuous limit of the sum
\begin{equation}
\begin{aligned}
    l \approx &- \int P(A, B) P_{\rm J} \log(\tilde{f}(A, B)) \\ &
    + P(A) P( B) (1 - P_{\rm J}) \log(1 - \tilde{f}(A, B)) dA dB.
\end{aligned}
\end{equation}
where the approximation approaches equality as the size of the training data set approaches infinity. During training the loss function is minimized and so we can find the function the network should converge to via the calculus of variations
\begin{equation}
    0 = \frac{\delta l}{\delta \tilde{f}} = \frac{P(A, B) P_{\rm J} }{\tilde{f}(A, B)}  - \frac{P(A) P( B) (1 - P_{\rm J})}{1 - \tilde{f}(A, B)},
\end{equation}
which can be rewritten as
\begin{equation}
    \tilde{f}(A, B) = \frac{\frac{P(A, B)P_{\rm J}}{ P(A) P( B) (1 - P_{\rm J})}}{1 + \frac{P(A, B)P_{\rm J}}{ P(A) P( B) (1 - P_{\rm J})}}.
\end{equation}
Recalling that the output of our network is defined such that $\tilde{f}(A, B) = S_\sigma(f(A, B))$ we see that 
\begin{equation}
    f(A, B) \rightarrow \log\left(\frac{P(A, B)P_{\rm J}}{ P(A) P( B) (1 - P_{\rm J})} \right),
\end{equation}
which when $P_{\rm J} = 0.5$ gives
\begin{equation}
    f(A, B) \rightarrow \log r,
\end{equation}
where in the limit of perfect training $f(A, B) = \log r $.

\section{Calibrating $R$ with NREs}
\label{sec:calibration_r}

As discussed above, a trained NRE outputs the log of the ratio
\begin{equation}
    r = \frac{P(A,B)}{P(A)P(B)}.
\end{equation}
It can be seen, trivially,
\begin{equation}
    r = R = \frac{P(D_A,D_B)}{P(D_A)P(D_B)} = \frac{\mathcal{Z}_{A,B}}{\mathcal{Z}_A \mathcal{Z}_B},
\end{equation}
if the inputs to the NRE $A$ and $B$ correspond to the datasets $D_A$ and $D_B$

We propose that the true observed tension $R_\mathrm{obs}$ is calculated using nested sampling \citep[e.g.][]{Handley_tensions_2019} or an alternative independent evidence estimation tool. Then we propose using the NRE to predict the in concordance $R$ distribution, against which one can calibrate $R_{\rm obs}$. A schematic of the NRE or \textsc{tensionnet} is shown in \cref{fig:tension_network}.

\begin{figure*}
    \centering
    \includegraphics{figs/figure2.pdf}
    \caption{Interpreting $R_\mathrm{obs}$ with NREs. The top row of the figure shows an example distribution of possible in concordance $R$ values. As we move to the right of the median of the distribution we move towards concordance and to the left, lower values of $\log R$, towards tension.
    The middle row of the figure shows the corresponding cumulative distribution function, and the bottom row shows how the tension statistic $T$ and concordance statistic $C$ vary with $\log R$ for this example. The observed $\log R_\mathrm{obs}$, its corresponding value on the CDF and its value on $T$ and $C$ are shown as green dashed lines. The shaded regions show the 1,2 and 3 $\sigma$ contours for both statistics with the darker region representing 1$\sigma$ and the lighter region 3$\sigma$.}
    \label{fig:interpretation}
\end{figure*}

In practice, our proposed calibration method is as follows;
\begin{enumerate}
    \item Generate a set of matched simulations, using the same models and prior used to evaluate $R_{\rm obs}$, of $D_A(\theta)$ and $D_B(\theta)$ where they share the same parameters. This gives us the set $s =\{D_A(\theta_i), D_B(\theta_i)\}_{i=0}^N$.
    \item We then shuffle one set of the simulations to give us $s^\prime = \{D_A(\theta_i), D_B(\theta_j)\}_{i \neq j = 0}^{N}$.
    \item We label the matched sets of data with a value of 1 and the mismatched data with a value of 0.
    \item We then shuffle our labelled matched and mismatched data and split this into training and validation data.
    \item We then train our Neural Ratio Estimator and perform early stopping using the validation data.
    \item Once trained we then generate a new set of matched datasets, $z =\{D_A(\theta_i), D_B(\theta_i)\}_{i=0}^N$, from the models covering the entire prior range and calculate their corresponding $\log R$ values with the NRE to recover the in concordance distribution.
    \item Given samples on this distribution $P(\log R)$ we then calculate an empirical CDF, $P(\log R < \log R^\prime)$ which along with the inverse survival function of the standard normal distribution can be used to translate $R$ into the desired prior calibrated $N\sigma$ measure of tension.
\end{enumerate}

The inverse survival function $z(\alpha)$ is defined as the probability that a random variable $X$ takes a value less than $x$.  Specifically, we are interested in the one-sided inverse survival function which for a standard normal distribution is
\begin{equation}
    z\bigg(\frac{\alpha}{2}\bigg) = \sqrt{2}\mathrm{erf}^{-1}\bigg(2 \bigg(1 - \frac{\alpha}{2}\bigg) -1\bigg).
\end{equation}

We can define a prior calibrated tension statistic from the CDF of the $\log R$ distribution
\begin{equation}
\begin{aligned}
    T = z\bigg(\frac{P(\log R < \log R^\prime)}{2}\bigg) = \sqrt{2}\mathrm{erf}^{-1}(1 - P(\log R < \log R^\prime)),
\end{aligned}
\end{equation}
If $P(\log  R< \log R^\prime) = 1$ then $T = 0$ and we should be concerned that are datasets are in perfect agreement. If $T=3$ for example, then we can say that the experiments are in $3\sigma$ tension. Conversely, we can define a concordance statistic
\begin{equation}
\begin{aligned}
    C & = z\bigg(\frac{(1-P(\log R < \log R^\prime))}{2}\bigg) \\& = \sqrt{2}\mathrm{erf}^{-1}(P(\log R < \log R^\prime)),
\end{aligned}
\end{equation}
where a value of $C = 3$ indicates a 3$\sigma$ agreement between the datasets. If $C$ becomes very large, then we would conclude that the data sets are in a suspicously high degree of agreement (see \cref{fig:interpretation}).

\section{Validating the NRE}
\label{sec:validation}

To demonstrate the robustness of our method, and some of its limitations, we first look at an example with an analytically tractable distribution of in concordance $\log R$ and compare this with the prediction from the NRE.

We begin by defining our prior and likelihood function in our example to be Gaussian and use a linear model for each of our observed datasets,
\begin{equation}
\begin{aligned}
    D = & M \theta + m \pm \sqrt{C} \\
    \mathcal{L}(D|\theta) = &\mathcal{N}(M \theta + m, C) \\
    \pi(\theta) = & \mathcal{N}(\mu, \Sigma)
\end{aligned}
\end{equation}
where $\theta$ are the model parameters, $M$ and $m$ define the data model and data samples can be drawn from the likelihood with covariance $C$. In the example that follows $M$, $m$ and $C$ are different for each experiment. $\mu$ and $\Sigma$ are the mean and covariance of our prior. In such a set-up the Bayesian evidence for each experiment and the joint observation is analytically tractable. For each experiment, the evidence is given by
\begin{equation}
    \mathcal{Z} = \mathcal{N}(m + M\mu, C + M\Sigma M^\prime).
\end{equation}
We use the \textsc{lsbi} package to evaluate these expressions \footnote{\url{https://github.com/handley-lab/lsbi}}.

We draw training data from $\mathcal{Z}_{AB} = P(D_A, D_B)$ for our NRE and for each pair of $D_A$ and $D_B$ in the test data we analytically calculate $R$ to build the `true' distribution that we are trying to predict with the trained NRE.

\subsection{Assessing the performance of the NRE}


The performance of NREs is known to degrade as the absolute value of the log ratio they are predicting increases. Therefore, we might expect the performance of the \textsc{tensionnet} to degrade with increasing prior width, and we test this by comparing the prediction from the NRE with the true distribution for a range of prior widths $\Sigma$.

We define $M$ to be a matrix of uniform random numbers between 0 and 1 of dimensions $d \times n$ where $d=50$ is the number of data points and $n=3$ is the number of dimensions. $m$ and $\mu$ are defined to be a vector of uniform random numbers between 0 and 1 of length $d$ and $C$ is a diagonal matrix of $0.01$. Where $M$ and $m$ vary, the prior defined by $\Sigma$ and $\mu$ is the same for both experiments. $\Sigma$ is a diagonal matrix, and we consider three different scenarios where $\Sigma = 0.1 \mathcal{I}, 1\mathcal{I}$ and $100\mathcal{I}$ where $\mathcal{I}$ is the identity matrix. 

For each $\Sigma$ we generate $500,000$ matched observations from experiment $A$ and experiment $B$ for training the NRE. We use an exponentially decaying learning rate with an initial value of $10^{-3}$, a step size of 1000 and a decay rate of 0.9. We use a ReLU activation function in the hidden layers, five hidden layers of 25 nodes each, a maximum number of epochs of 1000 with early stopping and a batch size of 1000. We use the ADAM optimizer for training. Once trained, we generate a new set of 5000 previously unseen in concordance observations from the models to put through the NRE and generate a predicted distribution of $\log R$.

The top panel of \cref{fig:validation_example} shows the predicted distributions (dashed lines) from the NRE versus the analytic distributions (solid lines) for different $\Sigma$. The solid black line shows the sigmoid activation function. The bottom three panels show the predicted versus true $\log R$ for each pair of data samples in the distribution. As the prior widens and $\log R$ becomes larger, the accuracy with which the distribution is recovered degrades as expected. Performance drops off, particularly for large prior widths, when $\log R > 10$. Caution needs to therefore be taken when using the NRE to calibrate values of $\log R \gg 10$. In such circumstances, one could consider reducing the width of the prior or running nested sampling on a handful of simulations to gauge how well the NRE is performing. If all one is interested in is the tension between different data sets, one could also choose one's prior so that $\log R$ is closer to 1 since the proposed tension metrics $T$ and $C$ are prior independent. For the orange distribution with $\Sigma=0.1\mathcal{I}$ and to some extent the purple distribution with $\Sigma = 1\mathcal{I}$, the NRE accurately recovers the $\log R$ distribution.

\begin{figure*}
    \centering
    \includegraphics{figs/figure3.pdf}
    \caption{To illustrate the performance of the \textsc{tensionnet} we hypothesise two experiments observing data that can be described with a linear model and a Gaussian likelihood function. By then defining our prior to also be Gaussian with a diagonal covariance $\Sigma$ we can analytically calculate the joint and individual evidences and the tension statistic $R$. We draw a test from the joint distribution $\mathcal{Z}(D_A,D_B)$ set which we use to analytically derive the in concordance $\log R$ distribution (solid lines, top panel) and predict the distribution from the NRE (dashed lines, top panel) for different prior widths. We also show the sigmoid activation function for reference. The bottom row shows the predicted versus true $\log R$ values for the test set for different prior widths. Performance begins to break down for $\log R > 10$ however, for narrower priors corresponding to lower values of $\Sigma$ the \textsc{tensionnet} correctly recovers the in concordance $\log R$ distribution.}
    \label{fig:validation_example}
\end{figure*}

\subsection{Calibrating out the prior}

Using the above example, we can also illustrate how the \textsc{tensionnet} can be used to calibrate out the dependence of $R$ on the prior. In \cref{fig:lsbi-pior-dependence}, we keep our data model the same but change the prior width on our three parameters. Our observed dataset is drawn from the narrowest prior and kept the same throughout. We can clearly see that as the prior width increases, so does $R_\mathrm{obs}$ as expected. However, we can also see that the true distribution (purple) of in concordance $\log R$ values also shifts to higher values. When we use this distribution to calibrate $\log R_\mathrm{obs}$ into $T$ and $C$ the values are approximately constant regardless of the prior width. Calibrating against the predicted distribution from the NRE (orange) gives largely consistent results with some degradation in performance for the largest prior width as expected from the last section. We repeat the analysis five times and report the average values of $T$ and $C$ with an associated error for both the true and predicted distributions in \cref{fig:lsbi-pior-dependence}.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/figure5-lsbi-averages.pdf}
    \caption{Using the linear model described in \cref{sec:validation} we show how the in concordance $\log R$ distribution can be used to calibrate the prior dependence of the $R$ statistic. We also show how the predicted in concordance $R$ distribution from the \textsc{tensionnet} is largely consistent with the analytic distribution. The narrowest prior is on the top row and the widest on the bottom row. The first column shows the distribution of in concordance $\log R$ values calculated analytically in purple and as predicted by the NRE in orange. We also show the analytically calculated value of $\log R$ for a simulation drawn from the narrow prior as a red dashed line. The middle column shows the CDFs derived from the two in concordance distributions and as horizontal dashed lines the value of the CDF at $R_\mathrm{obs}$ according to the analytic (purple) and NRE (orange) distributions. The final column shows the average values over five runs of $T$ and $C$ derived using the true analytic distributions and the NRE for each prior with an associated error. From the first column of the figure, we see clearly see the prior dependence of the $\log R$ distribution. However, we can also see that the values of $T$ and $C$ predicted with the true in concordance $\log R$ distribution remain approximately constant regardless of the prior width. We can also see that the calibrating with the predicted and analytic distributions give largely consistent results.}
    \label{fig:lsbi-pior-dependence}
\end{figure*}

\section{Cosmological Examples}
\label{sec:cosmological_examples}
\subsection{Toy 21-cm Cosmology}
\label{sec:toy_21cm}

Observers in the field of 21-cm Cosmology are aiming to detect an information rich redshifted signal from neutral hydrogen from the Cosmic Dawn and Epoch of Reionization \citep[see][for reviews of the field]{Furlanetto2006, Barkana2016, Mesinger2019, Liu2020}. The signal is observed in the radio band, and  can in theory be detected as a sky-averaged 21-cm signal \citep[e.g.][]{EDGES, SARAS3, Acedo2022REACH}. It has a complex dependence on the astrophysics of the early Universe \citep[e.g.][]{Mirocha2014ARES, Mesinger201121cmfast, Reis2020radioGalaxies, Reis2021Lyalpha, GesseyJones2022IMF, Skider2024LineSight, Pochinda2023Joint, GesseyJones2024Joint, Munoz2023Zeus}, but it can be approximated by a Gaussian absorption feature \citep[e.g.][]{Anstey2021REACH} in the CMB spectrum akin to a spectra distortion. The key challenge in 21-cm cosmology is the separation of this signal from the dominant Galactic and extragalactic foregrounds, that the instruments also observe, whilst accounting for the non-uniform response of the instruments to the sky \citep{Anstey2021REACH}.

We ignore the effects of foregrounds and the instrument in our example, since we are focused on illustrating the performance of the \textsc{tensionnet}. We include Gaussian distributed noise in our simulated data (inspired by current observations \cite{EDGES, SARAS3}) and a Gaussian absorption feature
\begin{equation}
    \delta T_b = -A \exp \bigg( -\frac{(\nu - \nu_0)^2}{w^2} \bigg),
    \label{eq:gaussian_signal}
\end{equation}
where $A$ corresponds to the amplitude of the signal, $\nu_0$ to the central frequency and $w$ to the width.

Current observations of the sky-averaged 21-cm signal include a tentative detection by the EDGES collaboration \cite{EDGES} and an upper limit on the magnitude of the signal from SARAS3~\cite{SARAS3}. Analysis by the SARAS3 team suggested that these measurements are in tension with each other, and a number of works have discussed the possible presence of systematics in the EDGES data \cite{Hills2018Edges, Singh2019EDGES, Sims2020EDGES, Bevins2021maxsmooth}. As more experiments come online in the coming years \citep[e.g.][]{Acedo2022REACH} the assessment of tension and concordance between different observations is going to become crucial for the field.

\comment{
\begin{table}[]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
         $A_B/A_A$ & $T$ & $C$\\
         \hline
         \hline
         0.75 & $2.154^{+0.073}_{-0.063}$ & $0.039^{+0.008}_{-0.006}$ \\
         \hline
         1.00 & $0.043^{+0.018}_{-0.027}$ & 
         $2.120^{+0.218}_{-0.207}$\\
         \hline
         1.25 &$3.35^{+0.158}_{-0.001}$ & $0.001 \pm 0.001$\\
         \hline
    \end{tabular}
    \caption{Caption}
   \label{tab:my_label}
\end{table}
}

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/figure4.pdf}
    \caption{To further illustrate the application of NREs to the calibration of $R$ we use a toy example inspired by 21-cm cosmology. \textbf{Left Panel:} We simulate an experiment observing a Gaussian absorption trough as a function of frequency (black line) and three different scenarios in which another experiment measures a 21-cm signal with either the same or different amplitudes in a different band (red lines). To each observation, we add Gaussian random noise with a standard deviation of 25 mK (shown in grey and motivated by current observations \citep[e.g.][]{EDGES}). \textbf{Middle Panel:} We train the NRE on simulated observations of the signal by both experiments, covering a wide prior range of signal parameters. We use the NRE to evaluate the possible distribution of in concordance $\log R$ values, which is shown in the middle panel. We plot the observed $\log R$ for each pair of observations from experiment A and B. \textbf{Right Panel:} Finally, we show the CDF of the in concordance $\log R$ distribution in the right panel of the figure and the corresponding CDF values for each pair of observations. We find that for the two in tension observations the  $T=2.989^{+0.167}_{-0.060}$ and $T = 2.147^{+0.056}_{-0.089}$ and for the in concordance observations $C = 0.864^{+0.107}_{-0.076}$ and $T = 0.507^{+0.063}_{-0.078}$. The results are in agreement with our expectations given the relative amplitudes of the observed signals, and the example demonstrates the application of the \textsc{tensionnet} on a problem with no analytically tractable in concordance $\log R$ distribution.}
    \label{fig:toy_example}
\end{figure*}

We simulate observations of the sky-averaged 21-cm signal from two different experiments in different frequency ranges. We hypothesise that the 21-cm signal has a depth of 0.2 K, a central frequency of 78 MHz and a width of 10 MHz. In our example, the first experiment (Exp. A) has made a detection of the signal with Gaussian distributed noise with a standard deviation of 25~mK over the frequency range $60-90$ MHz with a channel width of $\approx 0.3$~MHz (see top left panel of \cref{fig:toy_example}). We then hypothesise a series of scenarios where a second experiment (Exp. B) has observed the 21-cm signal in the frequency range $80 - 120$ MHz with a channel width of $\approx 0.4$~MHz with the same central frequency and width but a different magnitude $A = [ 0.15, 0.2, 0.25]$ K such that the observations are in tension, concordance and tension respectively. We add 25 mK Gaussian random noise to the data from experiment B.
 
We fit each pair of observations using the nested sampling implementation \textsc{polychord} \citep{Handley2015polychorda, Handley2015polychordb} to assess $R_\mathrm{obs}$. We use \cref{eq:gaussian_signal} as our model, $M$ for the data, $D$ and use a Gaussian likelihood function
\begin{equation}
    \log \mathcal{L} = \sum_i -\frac{1}{2} \log 2\pi \sigma^2 - \frac{1}{2} \frac{(D_i - M_i)^2}{\sigma^2},
\end{equation}
where the sum is over observation frequency and $\sigma$ is the standard deviation of the noise, which we fit as a free parameter. The prior is uniform on $A$ between $0.0 - 4.0$ K, $\nu_0$ between $60 -80$ MHz, $w$ between $5 - 40$ MHz and $\sigma$ between $0.001 - 0.1$~K. The combination of our likelihood and prior and the fact that our model is non-linear makes the in concordance $\log R$ distribution analytically intractable. It can only be accessed in a reasonable amount of time through the \textsc{tensionnet}. One could of course evaluate the distribution with 1000s of Nested Sampling runs, but this would be computationally expensive.

We generate 200,000 mock observations of the 21-cm signal for both experiments with the same sets of parameters from the prior. We then shuffle these datasets to create a corresponding set of in tension `observations' giving us a set of 400,000 simulations. We use $80\%$ of this to train the NRE and the rest to perform early stopping.

Once trained, we generate 5000 pairs of observations of the same signal by both experiment with parameters drawn randomly from the prior range to evaluate the in concordance  $\log R$ distribution. From this distribution, we can calculate an empirical CDF and compare the observed $R$ statistic for the three pairs of observations. Nested sampling returns an error on the Bayesian evidence, which can then be propagated forward through to $\log R_\mathrm{obs}$ and the tension statistics $T$ and $C$. For the two in tension datasets we find $T=2.989^{+0.167}_{-0.060}$ and $T = 2.147^{+0.056}_{-0.089}$ and for the in concordance case when both experiments observe the same signal $C = 0.864^{+0.107}_{-0.076}$ and $T = 0.507^{+0.063}_{-0.078}$. This is in agreement with our expectations, given the amplitude of the signals in the different data sets, and demonstrates that the \textsc{tensionnet} performs well. The results are summarised in \cref{fig:toy_example}.

\subsection{DESI and SDSS}
\label{sec:toy_cosmo}

We next investigate the tension between the Baryon Acoustic Oscillations~(BAO) cosmological constraints from the Sloan Digital Sky Survey~(SDSS) \cite{Alam2015SDSSDR12, Ahumada2020SDSSDR16} and the recent Dark Energy Spectroscopic Instrument~(DESI) data release \cite{adame2024desiCosmologyBAO}.

Before recombination when photons and baryons were coupled via Thomson scattering, oscillations were set up in the hot plasma by the competing forces of gravity and radiation pressure. Spherical density perturbations in the coupled plasma propagated outwards as acoustic waves. Once the photons and the baryons decouple at recombination, these acoustic waves stop travelling through the baryon fluid and the scale of the wave is imprinted in the matter distribution. The scale of the acoustic waves at recombination is known as the sound horizon. The photons free stream and form the CMB. Since the baryons and dark matter are coupled by gravity, the acoustic waves imprint a preferential scale for structure formation and the distance between two galaxies in the later Universe. The BAO scale is hence a standard ruler, and observations of it can be used to constrain the expansion rate of and the matter density of the Universe \cite{Bassett2010BAO, Cuceu2019BAO}.

In practice, the BAO scale is estimated via the cross-correlation of the position of galaxies $\xi$ in large surveys like SDSS and DESI and shows up as a bump in $\xi(\theta)$ and $\xi(\Delta z)$ where $\theta$ is the angular separation of galaxies and $\Delta z$ the redshift separation. Angular scales on the sky $\theta$ are related to commoving physical sizes $\lambda$ by
\begin{equation}
    \theta = \frac{\lambda}{(1+z) D_A} = \frac{\lambda}{D_M},
\end{equation}
where $D_A$ is the angular diameter distance and $D_M$ is the comoving angular diameter distance also known as the transverse comoving distance. Similarly, physical size is related to redshift separation by
\begin{equation}
    \Delta z = \frac{\lambda H(z)}{c} = \frac{\lambda}{D_H},
\end{equation}
where $D_H$ is the Hubble distance, $c$ is the speed of light and $H(z)$ is the Hubble constant as a function of redshift. From $\xi(\theta)$ and $\xi(\Delta z)$ we can approximate the angular size of the BAO at a given redshift $\theta_\mathrm{BAO}$ and, given a large enough set of galaxy measurements as a function of redshift, the redshift separation $\Delta z_\mathrm{BAO}$. The comoving size of the BAO is equal to the sound horizon $\lambda = r_s$ at recombination when the photons and baryons decouple. BAO observations therefore give us a measure of $D_M/r_s$ and $D_H/r_s$ from which we can constrain cosmology.

The BAO signature appears in the cross-correlation of a number of different objects such as Luminous Red Galaxies~(LRG), Emission Line Galaxies~(ELG), quasars and the Lyman-$\alpha$ forest. Each class of objects probes a different redshift range, and measurements of $D_M/r_s$ and $D_H/r_s$ are ascribed to an effective redshift \cite{Bassett2010BAO}.

We generate theoretical models for the observables with \textsc{CAMB} \citep{Lewis1999CAMB, Lewis2002CAMB}, then taking advantage of the reported covariance estimates for the SDSS and DESI observations use analytic likelihoods, implemented with \textsc{scipy}, to generate noisy observations of the theory model.

There is a partial overlap in the redshift range and sky coverage of SDSS and DESI, and as such the full datasets include some of the same galaxies. Therefore, the surveys are correlated and if we want to perform a joint Bayesian inference of the datasets with tools like nested sampling to recover $R_\mathrm{obs}$ we need a joint likelihood function. Although the level of correlation between the datasets has been estimated \cite{adame2024desiLyaBAO, adame2024desiCosmologyBAO}, the derivation of a joint likelihood is beyond the scope of this paper and has not yet been attempted in the literature.

An alternative approach is to build a joint SDSS and DESI dataset by selecting data points from one survey or the other at each sampled effective redshift. In \cite{adame2024desiCosmologyBAO} the authors demonstrate this idea by selecting SDSS observations below $z=0.6$ and DESI observations above $z=0.6$ to maximise the effective volume covered by the joint dataset. In our analysis we use
\begin{itemize}
    \item SDSS LRG at $z_\mathrm{eff} = 0.38$ and $0.51$
    \item DESI LRG at $z_\mathrm{eff} = 0.706$
    \item DESI LRG-ELG at $z_\mathrm{eff} = 0.930$
    \item DESI ELG at $z_\mathrm{eff} = 1.317$
\end{itemize}
and the combined dataset is shown in \cref{fig:BAO-data}.
A more complete analysis can be pursued in the future when correlated likelihoods become available.
Some tension, at approximately 3$\sigma$ level, has been observed between SDSS and DESI at an effective redshift of $z_\mathrm{eff}\approx0.7$ \cite{adame2024desiTension},
although this was not arrived at via a joint analysis but rather an assessment of the individual measurements and the correlation between the datasets. We do not expect to see this tension in our analysis, as we are just considering the DESI measurement at $z_\mathrm{eff}\approx0.7$.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/desi_sdss_bao.png}
    \caption{The composite BAO dataset used in this work from SDSS and DESI observations. Following the discussion in \cite{adame2024desiCosmologyBAO} we curate the dataset by taking SDSS observations of the BAO scale from Luminous Red Galaxies~(LRG, crosses) below $z=0.6$ (grey shaded region) and high redshift observations of Luminous Red Galaxies and Emission Line Galaxies~(ELG; combination of ELG and LRG as circles and ELG on their own as triangle markers) from DESI (blue shaded region). The measurements of $D_M/r_s$ are shown by the orange markers and the measurements of $D_H/r_s$ as purple markers.}
    \label{fig:BAO-data}
\end{figure*}

We constrain the baryon density $\Omega_b h^2$, dark matter density $\Omega_c h^2$, the slope and amplitude of the matter power spectrum $n_s$ and $\log 10^{10} A_s$ and the value of $h = \frac{H_0}{100~{\rm km~s}^{-1}~{\rm Mpc}^{-1}}$. We fix the value of $\tau$ to the best fit value from the Planck 2018 analysis of $0.055$ \cite{Planck2018}. The prior is uniform on $\Omega_b h^2$ between $0.01 - 0.085$, $\Omega_c h^2$ between $0.08 - 0.21$, $n_s$ between $0.8 - 1.2$, $\log 10^{10} A_s$ between $2.6 - 3.8$ and $h$ between $0.5 - 0.9$. It is motivated by the prior in \cite{Handley_tensions_2019}, which is somewhat motivated by the default priors for \textsc{CosmoMC}~\footnote{https://cosmologist.info/cosmomc/}, and designed to encompass the Planck and Dark Energy Survey Y1 posteriors. As discussed in \cite{Handley_tensions_2019}, however, there is nothing particularly special about this prior and in practice it could be broadened or narrowed without causing any objections in the community.
For each measurement of the BAO signature $D$ our likelihood is Gaussian, as in \cite{Cuceu2019BAO}, with a covariance given by the measured covariance $\Sigma$.

The SDSS data is available at \url{https://www.sdss4.org/dr17/} and the DESI data has been reported in \cite{adame2024desiCosmologyBAO}. Both datasets have been collected together as part of the \textsc{COBAYA} cosmological likelihood code \footnote{\url{https://cobaya.readthedocs.io/en/latest/likelihood_bao.html}}. Using nested sampling and \textsc{CAMB}, we find $\log R_\mathrm{obs} =2.57 \pm 0.30$. Since $R_{\rm obs} < 10$ we are not worried about the NRE saturation that was previously discussed.

To train the NRE, we generate 100,000 examples of in concordance observations from SDSS and DESI. We then separate out 10\% of these for testing and shuffle the remaining $90\%$ to create a set of 180,000 matched and mismatched observations. These are then split into training and validation datasets of 120,600 and 59,400 (33\%) observations respectively. We use an exponentially decaying learning rate scheduler with an initial learning rate of $10^{-3}$, a step size of $1000$ and a decay rate of $0.9$. We train for a maximum of 1000 epochs with a batch size of 1000 and a patience of 50. We use L1 kernel regularization to improve the performance. We standardize the simulations at each redshift using the mean and standard deviation of the training data.


We group together the measurements of $D_M/r_s$ from DESI and SDSS at the different effective redshifts and compress them down into a smaller latent space. We do the same with the measurements of $D_H/r_s$ before passing them to the NRE. We find that compressing the data in this way works better than directly passing the raw data to the NRE. This initial step of keeping the measurements of $D_M/r_s$ and $D_H/r_s$ separate allows the NRE to learn the trends, like those seen in \cref{fig:BAO-data}, in each variable as a function of redshift before mixing information from the two together. The compression networks have three layers of 5, 5 and 2 hidden nodes and the NRE has 2 layers of 4 nodes each. The compression layers and the NRE are trained together. The architecture of the network can be seen in \cref{fig:bao-nre}.

\begin{figure*}
    \centering
    \begin{tikzpicture}[rednode/.style={circle, draw=red!60, fill=red!5, very thick,                 minimum size=3mm, node distance=0.1cm and 1cm},
                bluenode/.style={circle, draw=blue!60, fill=blue!5, very thick, minimum size=3mm, node distance=0.1cm and 1cm},
                greennode/.style={circle, draw=green!60, fill=green!5, very thick, minimum size=3mm},
                remember picture]
        \node (0) {};

        \node[rednode, above=of 0, align=center](layer1_center1) {};
        \node[rednode, below=of layer1_center1, align=center](layer1_center2) {};
        \node[rednode, above=of layer1_center1, align=center](layer1_top2) {};
        \node[rednode, below=of layer1_center2, align=center](layer1_bottom1) {};

        \node[rednode, left=of layer1_top2, align=center, ](hl1) {};
        \node[rednode, left=of layer1_center1, align=center](hl2) {};
        \node[rednode, left=of layer1_center2, align=center](hl3) {};
        \node[rednode, left=of layer1_bottom1, align=center](hl4) {};
        
        \node[bluenode, left=of hl1, align=center, yshift=0.25cm](compress_out1) {};
        \node[bluenode, above=of compress_out1, align=center](compress_out2) {};

        \node[bluenode, above left=of compress_out1](compress1_layer23){};
        \node[bluenode, above =of compress1_layer23](compress1_layer22){};
        \node[bluenode, above =of compress1_layer22](compress1_layer21){};
        \node[bluenode, below =of compress1_layer23](compress1_layer24){};
        \node[bluenode, below =of compress1_layer24](compress1_layer25){};

        \node[bluenode, left=of compress1_layer23](compress1_layer13){};
        \node[bluenode, left=of compress1_layer22](compress1_layer12){};
        \node[bluenode, left=of compress1_layer21](compress1_layer11){};
        \node[bluenode, left=of compress1_layer24](compress1_layer14){};
        \node[bluenode, left=of compress1_layer25](compress1_layer15){};

        \node[bluenode, left=of compress1_layer13](compress1_in3){};
        \node[bluenode, left=of compress1_layer12](compress1_in2){};
        \node[bluenode, left=of compress1_layer11](compress1_in1){};
        \node[bluenode, left=of compress1_layer14](compress1_in4){};
        \node[bluenode, left=of compress1_layer15](compress1_in5){};

        \foreach \x in {compress1_layer21, compress1_layer22, compress1_layer23, compress1_layer24, compress1_layer25}{
        \foreach \y in {compress_out1, compress_out2}{
        \draw[->](\x.east)--(\y.west);}}

        \foreach \x in {compress1_layer11, compress1_layer12, compress1_layer13, compress1_layer14, compress1_layer15}{
        \foreach \y in {compress1_layer21, compress1_layer22, compress1_layer23, compress1_layer24, compress1_layer25}{
        \draw[->](\x.east) -- (\y.west);}}

        \foreach \x in {compress1_in1, compress1_in2, compress1_in3, compress1_in4, compress1_in5}{
        \foreach \y in {compress1_layer11, compress1_layer12, compress1_layer13, compress1_layer14, compress1_layer15}{
        \draw[->](\x.east) -- (\y.west);}}
        
        \node[bluenode, left=of hl4, align=center, yshift=-0.25cm](compress2_out1) {};
        \node[bluenode, below=of compress2_out1,  align=center](compress2_out2) {};

        \node[bluenode, below left=of compress2_out1](compress2_layer23){};
        \node[bluenode, above =of compress2_layer23](compress2_layer22){};
        \node[bluenode, above =of compress2_layer22](compress2_layer21){};
        \node[bluenode, below =of compress2_layer23](compress2_layer24){};
        \node[bluenode, below =of compress2_layer24](compress2_layer25){};

        \node[bluenode, left=of compress2_layer23](compress2_layer13){};
        \node[bluenode, left=of compress2_layer22](compress2_layer12){};
        \node[bluenode, left=of compress2_layer21](compress2_layer11){};
        \node[bluenode, left=of compress2_layer24](compress2_layer14){};
        \node[bluenode, left=of compress2_layer25](compress2_layer15){};

        \node[bluenode, left=of compress2_layer13](compress2_in3){};
        \node[bluenode, left=of compress2_layer12](compress2_in2){};
        \node[bluenode, left=of compress2_layer11](compress2_in1){};
        \node[bluenode, left=of compress2_layer14](compress2_in4){};
        \node[bluenode, left=of compress2_layer15](compress2_in5){};

        \foreach \x in {compress2_layer21, compress2_layer22, compress2_layer23, compress2_layer24, compress2_layer25}{
        \foreach \y in {compress2_out1, compress2_out2}{
        \draw[->](\x.east)--(\y.west);}}

        \foreach \x in {compress2_layer11, compress2_layer12, compress2_layer13, compress2_layer14, compress2_layer15}{
        \foreach \y in {compress2_layer21, compress2_layer22, compress2_layer23, compress2_layer24, compress2_layer25}{
        \draw[->](\x.east) -- (\y.west);}}

        \foreach \x in {compress2_in1, compress2_in2, compress2_in3, compress2_in4, compress2_in5}{
        \foreach \y in {compress2_layer11, compress2_layer12, compress2_layer13, compress2_layer14, compress2_layer15}{
        \draw[->](\x.east) -- (\y.west);}}
        
        \node[greennode, right=of layer1_center1, text width=0.7cm, align=center, yshift=-0.25cm](output_1) {$\log R$};

        \foreach \x in {compress_out1, compress_out2, compress2_out1, compress2_out2}{
            \foreach \y in {hl1, hl2, hl3, hl4}{
            \draw[->](\x.east) -- (\y.west);}}
        
        \foreach \x in {hl1, hl2, hl3, hl4}{
            \foreach \y in {layer1_center1, layer1_center2, layer1_top2, layer1_bottom1}{
                \draw[->](\x.east) -- (\y.west);}}
        
        \draw[->](layer1_center1.east) -- (output_1.west);
        \draw[->](layer1_center2.east) -- (output_1.west);
        \draw[->](layer1_top2.east) -- (output_1.west);
        \draw[->](layer1_bottom1) -- (output_1.west);

        \foreach \x/\label/\c in {compress1_in1/\tiny SDSS LRG $z_\mathrm{eff}=0.38$/red!20, compress1_in2/\tiny SDSS LRG $z_\mathrm{eff}=0.51$/red!20, compress1_in3/\tiny DESI LRG $z_\mathrm{eff}=0.706$/blue!20, compress1_in4/\tiny DESI LRG-ELG $z_\mathrm{eff}=0.930$/blue!20, compress1_in5/\tiny DESI LRG $z_\mathrm{eff}=1.317$/blue!20}{
        \node[draw, rectangle, left=of \x, text width=3cm, align=center, node distance=0.1cm and 0.1cm, fill=\c, xshift=0.9cm]{\label};
        }

        \foreach \x/\label/\c in {compress2_in1/\tiny SDSS LRG $z_\mathrm{eff}=0.38$/red!20, compress2_in2/\tiny SDSS LRG $z_\mathrm{eff}=0.51$/red!20, compress2_in3/\tiny DESI LRG $z_\mathrm{eff}=0.706$/blue!20, compress2_in4/\tiny DESI LRG-ELG $z_\mathrm{eff}=0.930$/blue!20, compress2_in5/\tiny DESI LRG $z_\mathrm{eff}=1.317$/blue!20}{
        \node[draw, rectangle, left=of \x, text width=3cm, align=center, node distance=0.1cm and 0.1cm, fill=\c, xshift=0.9cm]{\label};
        }

        \node[rectangle, left=of compress1_in3, text width=1cm, align=center, node distance=0.1cm and 0.1cm, xshift=-3cm](dm){$D_M/r_s$};

        \node[ rectangle, right=of dm, text width=1cm, align=center, node distance=0.1cm and 0.1cm, xshift=-1.4cm]{\Huge \{};

        \node[rectangle, left=of compress2_in3, text width=1cm, align=center, node distance=0.1cm and 0.1cm, xshift=-3cm](dh){$D_H/r_s$};

        \node[rectangle, right=of dh, text width=1cm, align=center, node distance=0.1cm and 0.1cm, xshift=-1.4cm]{\Huge \{};
        
        
    \end{tikzpicture}
    \caption{An exact diagram of hidden layer structure in the DESI-SDSS \textsc{tensionnet}. We find that combining and compressing the information in the measurements of $D_M/r_s$ and $D_H/r_s$ from DESI and SDSS into a latent space before mixing information from the two measurements improves the performance of the NRE. The compression networks (in blue) and the NRE (in red) are trained together under the same binary cross entropy loss function.}
    \label{fig:bao-nre}
\end{figure*}

We train the network on the same training data five times with different random initial seeds to assess the consistency of our results. The corresponding values of $T$ are shown in \cref{fig:bao_sigmaD}. We find that on average, $T = 1.22 \pm 0.20$ between the combined SDSS and DESI datasets. We show an example of the calibration performed for one of the training and calibration runs in \cref{fig:bao-calibration} along with the constraints on $\Omega_m$ and $H_0 r_s$. We find no significant tension between the SDSS measurements of the BAO scale at $z_\mathrm{eff} = 0.38$ and $0.51$ and the DESI measurements at higher redshifts of $z_\mathrm{eff} = 0.706, 0.930$ and $1.317$.

\begin{figure}
    \centering
    \includegraphics{figs/desi_sdss_sigma.pdf}
    \caption{We repeat training of our NRE five times on simulations of the data from SDSS and DESI and use the predicted distributions to evaluate $T$. If our network was ill-converged, or we had two little training data, then the recovered distribution of in concordance $R$ values would vary significantly. As a result, the calculated value of $T$ would be inconsistent, and we would see a large scatter in the reported values. Instead, we see that for the SDSS+DESI analysis, $T$ is consistent across the different training runs. On average, we find that $T = 1.22 \pm 0.20$.}
    \label{fig:bao_sigmaD}
\end{figure}

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/desi_sdss_run4.pdf}
    \caption{\textbf{Left Panel:} The predicted distribution of in concordance $\log R$ values for the curated SDSS and DESI dataset analysed in this work. The red dashed line shows the value of $\log R_\mathrm{obs}$ for the observed data calculated with nested sampling. The shaded region shows the error on this value from the nested sampling algorithm. \textbf{Middle Panel:} The CDF corresponding to the in concordance $\log R$ distribution. Calibrating $\log R_\mathrm{obs}$ (red dashed line and shaded region) in to $\sigma$s of tension gives $T = 1.23^{+0.21}_{-0.20}$. \textbf{Right Panel:} The constraints on the matter overdensity $\Omega_m$ and the combination of the Hubble constant $H_0$ and sound horizon $r_s$ from analysis of the DESI and SDSS datasets. Here, the SDSS data comprises observations $z<0.6$ and the DESI data observations with $z>0.6$. Our results are slightly different to those presented in Fig. 2 of \cite{adame2024desiCosmologyBAO} because we have used a different prior and not included the quasar measurements from DESI or the Lyman-$\alpha$ measurements from both surveys.}
    \label{fig:bao-calibration}
\end{figure*}

\section{Limitations}
\label{sec:limitations}

As with all simulation based inference methods, the success of the \textsc{tensionnet} is dependent on how well the simulations represent the true observed datasets. In some respects, the method is also limited by the need for simulations. For example, to assess the tension between supernova observations of $H_0$ and CMB measurements using the $R$ statistic and the \textsc{tensionnet} one would need to be able to simulate the observations in a consistent framework. While work is being pursued in this direction \citep[e.g.][]{Watts2023Cosmoglobe, Karchev2024supernova} it is a notoriously difficult problem.

It is also currently difficult to verify the output of the \textsc{tensionnet}. In practice, one could run a coverage test on the recovered distribution of $\log R$ \cite{Lemos2023CoverageTest}. However, this only tells you how self-consistent the recovered distribution is and not whether it is centred around the correct $\log R$ value. One way to test this is to take a number of simulated datasets in the predicted distribution and calculate their $\log R$ value via an independent method such as nested sampling. An alternative validation approach is to repeat the NRE training to check for stability as in \cref{fig:bao_sigmaD}.

As demonstrated in \cref{sec:validation}, the \textsc{tensionnet} is limited by the NREs ability to predict extreme values of $\log R$. Sensible choices of prior distributions can help alleviate this issue, and the validation methods discussed above can help build confidence in the predicted distribution.

\section{Conclusions}
\label{sec:conclusions}

Estimating tension between different datasets is an important part of the scientific process and has become integral to the analysis of cosmological and astrophysical data. By correctly quantifying tension between different experiments, we are able to better understand our instruments and identify gaps in our knowledge. Commonly encountered examples of tension in cosmology are the $H_0$ and $\sigma_8$ tensions, although other examples exist, including in the field of 21-cm cosmology. 

A number of ways to quantify tension have been proposed including eigentension, goodness of fit degradation and Suspiciousness and these can often be translated into $\sigma$s of tension where $\sigma$ is the standard deviation of a normal distribution. A Bayesian way to quantify tension is with the tension statistic $R$ which encodes our increased confidence in one experiment's measured data given observations from another. Formerly, $R$ is the ratio of joint Bayesian evidence to the product of the individual evidences for two datasets under a common model and prior. It is symmetric, parameterisation invariant and dimensionally consistent, however, it has a non-trivial dependence on the prior. $\log R$ is typically interpreted as indicating tension if $R \ll 1$ and concordance if $R \gg 1$ or via a Jeffery's scale, neither of which properly account for the prior dependence.

For any pair of experiments observing the same physics, any model for the data and any prior distribution, there is a distribution of in concordance $\log R$ values. Having access to this distribution allows you to calibrate out the prior dependence from the observed $R$ and robustly convert the statistic into $\sigma$s of tension or concordance. Unfortunately, for most problems, this distribution is not analytically accessible. In this paper, we have shown that it can be readily accessed with simulations of the experimental observables and neural ratio estimation.

We demonstrated the application of NREs to the calibration of $R$ using toy examples and observations of the BAO scale from SDSS and DESI. By selecting observations of the BAO scale from each survey at specific effective redshifts, we avoid having to worry about the correlation between the observations whilst maximising the effective volume of the combined survey. We find no significant tension between the SDSS Luminous Red Galaxy measurements at $z_\mathrm{eff} = 0.38$ and $0.51$ and the DESI Luminous Red Galaxy measurements and Emission Line Galaxy measurements at $z_\mathrm{eff} = 0.706, 0.930$ and $1.317$. 

In \cite{adame2024desiTension} some tension has been seen between the SDSS and DESI datasets at $z_\mathrm{eff} \approx 0.7$. In practice, this could be assessed with the \textsc{tensionnet} in the future should a correlated likelihood function become available for calculating the observed $R$ with nested sampling.

Like all simulation based methods, the \textsc{tensionnet} is limited by the accuracy of the simulated observations and indeed by our ability to simulate the data in the first instance. We also find that performance of the NRE degrades as the prior widens, and sensible prior choices need to be made. We suggest that repeated training of the NRE and evaluation of $R$ for a handful of simulations with nested sampling or an independent evidence estimation tool can be done to validate the results.

We have shown that neural ratio estimators offer a cheap and effective way to access the in concordance $\log R$ distribution needed to calibrate out the prior dependence of the $R$ statistic. While acknowledging the limitations of this method, we believe it offers a promising step towards simulation based tension quantification. We expect that the method proposed in this paper will be broadly applicable beyond cosmology in other fields where tensions appear \cite[e.g.][]{CDF2022}.

\section{Acknowledgements}

HTJB acknowledges support from the Kavli Institute for Cosmology Cambridge and the Kavli Foundation. WJH thanks the Royal Society for their support through their University Research Fellowships. TGJ acknowledges the support of the Science and Technology Facilities Council (UK) through grant ST/V506606/1 and the Royal Society.

This work used the DiRAC Data Intensive service (CSD3, project number ACSP289) at the University of Cambridge, managed by the University of Cambridge University Information Services on behalf of the STFC DiRAC HPC Facility (www.dirac.ac.uk). The DiRAC component of CSD3 at Cambridge was funded by BEIS, UKRI and STFC capital funding and STFC operations grants. DiRAC is part of the UKRI Digital Research Infrastructure

\section{Data Availability}
The code and data used in this paper are available at \url{https://github.com/htjb/tension-networks}.

\bibliographystyle{apsrev4-2-titles}
\bibliography{journals, ref}

\appendix

\end{document}

```

4. **Bibliographic Information:**
```bbl
%apsrev4-2.bst 2019-01-14 (MD) hand-edited version of apsrev4-1.bst
%Control: key (0)
%Control: author (72) initials jnrlst
%Control: editor formatted (1) identically to author
%Control: production of article title (-1) disabled
%Control: page (1) range
%Control: year (1) truncated
%Control: production of eprint (0) enabled
\begin{thebibliography}{75}%
\makeatletter
\providecommand \@ifxundefined [1]{%
 \@ifx{#1\undefined}
}%
\providecommand \@ifnum [1]{%
 \ifnum #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \@ifx [1]{%
 \ifx #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \natexlab [1]{#1}%
\providecommand \enquote  [1]{``#1''}%
\providecommand \bibnamefont  [1]{#1}%
\providecommand \bibfnamefont [1]{#1}%
\providecommand \citenamefont [1]{#1}%
\providecommand \href@noop [0]{\@secondoftwo}%
\providecommand \href [0]{\begingroup \@sanitize@url \@href}%
\providecommand \@href[1]{\@@startlink{#1}\@@href}%
\providecommand \@@href[1]{\endgroup#1\@@endlink}%
\providecommand \@sanitize@url [0]{\catcode `\\12\catcode `\$12\catcode `\&12\catcode `\#12\catcode `\^12\catcode `\_12\catcode `\%12\relax}%
\providecommand \@@startlink[1]{}%
\providecommand \@@endlink[0]{}%
\providecommand \url  [0]{\begingroup\@sanitize@url \@url }%
\providecommand \@url [1]{\endgroup\@href {#1}{\urlprefix }}%
\providecommand \urlprefix  [0]{URL }%
\providecommand \Eprint [0]{\href }%
\providecommand \doibase [0]{https://doi.org/}%
\providecommand \selectlanguage [0]{\@gobble}%
\providecommand \bibinfo  [0]{\@secondoftwo}%
\providecommand \bibfield  [0]{\@secondoftwo}%
\providecommand \translation [1]{[#1]}%
\providecommand \BibitemOpen [0]{}%
\providecommand \bibitemStop [0]{}%
\providecommand \bibitemNoStop [0]{.\EOS\space}%
\providecommand \EOS [0]{\spacefactor3000\relax}%
\providecommand \BibitemShut  [1]{\csname bibitem#1\endcsname}%
\let\auto@bib@innerbib\@empty
%</preamble>
\bibitem [{\citenamefont {{Knox}}\ and\ \citenamefont {{Millea}}(2020)}]{knox2020HubbleHunters}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {{Knox}}}\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Millea}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Hubble constant hunter's guide}}},\ }\href {https://doi.org/10.1103/PhysRevD.101.043533} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {101}},\ \bibinfo {eid} {043533} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1908.03663} {arXiv:1908.03663 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Efstathiou}}(2020)}]{Efstathiou2020LockdownH0}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Efstathiou}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{A Lockdown Perspective on the Hubble Tension (with comments from the SH0ES team)}}},\ }\href {https://doi.org/10.48550/arXiv.2007.10716} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2007.10716}} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/2007.10716} {arXiv:2007.10716 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Amon}}\ and\ \citenamefont {{Efstathiou}}(2022)}]{Amon2022s8}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Amon}}}\ and\ \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Efstathiou}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{A non-linear solution to the S$_{8}$ tension?}}},\ }\href {https://doi.org/10.1093/mnras/stac2429} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {516}},\ \bibinfo {pages} {5355--5366} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2206.11794} {arXiv:2206.11794 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Preston}}\ \emph {et~al.}(2023)\citenamefont {{Preston}}, \citenamefont {{Amon}},\ and\ \citenamefont {{Efstathiou}}}]{Preston2023s8}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Preston}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Amon}}},\ and\ \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Efstathiou}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{A non-linear solution to the S$_{8}$ tension - II. Analysis of DES Year 3 cosmic shear}}},\ }\href {https://doi.org/10.1093/mnras/stad2573} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {525}},\ \bibinfo {pages} {5554--5564} (\bibinfo {year} {2023})},\ \Eprint {https://arxiv.org/abs/2305.09827} {arXiv:2305.09827 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Dark Energy Survey and Kilo-Degree Survey Collaboration}}(2023)}]{Abbott2023DESKIDS}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{Dark Energy Survey and Kilo-Degree Survey Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{DES Y3 + KiDS-1000: Consistent cosmology combining cosmic shear surveys}}},\ }\href {https://doi.org/10.21105/astro.2305.17173} {\bibfield  {journal} {\bibinfo  {journal} {The Open Journal of Astrophysics}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {eid} {36} (\bibinfo {year} {2023})},\ \Eprint {https://arxiv.org/abs/2305.17173} {arXiv:2305.17173 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Singh}}\ \emph {et~al.}(2022{\natexlab{a}})\citenamefont {{Singh}}, \citenamefont {{Jishnu}}, \citenamefont {{Subrahmanyan}}, \citenamefont {{Udaya Shankar}}, \citenamefont {{Girish}}, \citenamefont {{Raghunathan}}, \citenamefont {{Somashekar}}, \citenamefont {{Srivani}},\ and\ \citenamefont {{Sathyanarayana Rao}}}]{Singh_SARAS3_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Singh}}}, \bibinfo {author} {\bibfnamefont {N.~T.}\ \bibnamefont {{Jishnu}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Subrahmanyan}}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Udaya Shankar}}}, \bibinfo {author} {\bibfnamefont {B.~S.}\ \bibnamefont {{Girish}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Raghunathan}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Somashekar}}}, \bibinfo {author} {\bibfnamefont {K.~S.}\ \bibnamefont {{Srivani}}},\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Sathyanarayana Rao}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{On the detection of a cosmic dawn signal in the radio background}}},\ }\href {https://doi.org/10.1038/s41550-022-01610-5} {\bibfield  {journal} {\bibinfo  {journal} {Nature Astronomy}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {pages} {607--617} (\bibinfo {year} {2022}{\natexlab{a}})},\ \Eprint
  {https://arxiv.org/abs/2112.06778} {arXiv:2112.06778 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Battye}}\ \emph {et~al.}(2015)\citenamefont {{Battye}}, \citenamefont {{Charnock}},\ and\ \citenamefont {{Moss}}}]{Battye_tensions_2015}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.~A.}\ \bibnamefont {{Battye}}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Charnock}}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Moss}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Tension between the power spectrum of density perturbations measured on large and small scales}}},\ }\href {https://doi.org/10.1103/PhysRevD.91.103508} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {91}},\ \bibinfo {eid} {103508} (\bibinfo {year} {2015})},\ \Eprint {https://arxiv.org/abs/1409.2769} {arXiv:1409.2769 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Handley}}(2021)}]{Handley2019Curvature}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Handley}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Curvature tension: Evidence for a closed universe}}},\ }\href {https://doi.org/10.1103/PhysRevD.103.L041301} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {103}},\ \bibinfo {eid} {L041301} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/1908.09139} {arXiv:1908.09139 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Peebles}}(1984)}]{Peebles1984OmegaM}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.~J.~E.}\ \bibnamefont {{Peebles}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Tests of cosmological models constrained by inflation}}},\ }\href {https://doi.org/10.1086/162425} {\bibfield  {journal} {\bibinfo  {journal} {\apj}\ }\textbf {\bibinfo {volume} {284}},\ \bibinfo {pages} {439--444} (\bibinfo {year} {1984})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Krauss}}\ and\ \citenamefont {{Turner}}(1995)}]{Krauss1995OmegaM}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.~M.}\ \bibnamefont {{Krauss}}}\ and\ \bibinfo {author} {\bibfnamefont {M.~S.}\ \bibnamefont {{Turner}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The cosmological constant is back}}},\ }\href {https://doi.org/10.1007/BF02108229} {\bibfield  {journal} {\bibinfo  {journal} {General Relativity and Gravitation}\ }\textbf {\bibinfo {volume} {27}},\ \bibinfo {pages} {1137--1144} (\bibinfo {year} {1995})},\ \Eprint {https://arxiv.org/abs/astro-ph/9504003} {arXiv:astro-ph/9504003 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Ostriker}}\ and\ \citenamefont {{Steinhardt}}(1995)}]{Ostriker1995OmegaM}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~P.}\ \bibnamefont {{Ostriker}}}\ and\ \bibinfo {author} {\bibfnamefont {P.~J.}\ \bibnamefont {{Steinhardt}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The observational case for a low-density Universe with a non-zero cosmological constant}}},\ }\href {https://doi.org/10.1038/377600a0} {\bibfield  {journal} {\bibinfo  {journal} {\nat}\ }\textbf {\bibinfo {volume} {377}},\ \bibinfo {pages} {600--602} (\bibinfo {year} {1995})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Efstathiou}}\ \emph {et~al.}(1990)\citenamefont {{Efstathiou}}, \citenamefont {{Sutherland}},\ and\ \citenamefont {{Maddox}}}]{Efstathiou1990OmegaM}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Efstathiou}}}, \bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Sutherland}}},\ and\ \bibinfo {author} {\bibfnamefont {S.~J.}\ \bibnamefont {{Maddox}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The cosmological constant and cold dark matter}}},\ }\href {https://doi.org/10.1038/348705a0} {\bibfield  {journal} {\bibinfo  {journal} {\nat}\ }\textbf {\bibinfo {volume} {348}},\ \bibinfo {pages} {705--707} (\bibinfo {year} {1990})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Riess}}\ \emph {et~al.}(1998)\citenamefont {{Riess}}, \citenamefont {{Filippenko}}, \citenamefont {{Challis}}, \citenamefont {{Clocchiatti}}, \citenamefont {{Diercks}}, \citenamefont {{Garnavich}}, \citenamefont {{Gilliland}}, \citenamefont {{Hogan}}, \citenamefont {{Jha}}, \citenamefont {{Kirshner}}, \citenamefont {{Leibundgut}}, \citenamefont {{Phillips}}, \citenamefont {{Reiss}}, \citenamefont {{Schmidt}}, \citenamefont {{Schommer}}, \citenamefont {{Smith}}, \citenamefont {{Spyromilio}}, \citenamefont {{Stubbs}}, \citenamefont {{Suntzeff}},\ and\ \citenamefont {{Tonry}}}]{Riess1998Accelerating}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~G.}\ \bibnamefont {{Riess}}}, \bibinfo {author} {\bibfnamefont {A.~V.}\ \bibnamefont {{Filippenko}}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Challis}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Clocchiatti}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Diercks}}}, \bibinfo {author} {\bibfnamefont {P.~M.}\ \bibnamefont {{Garnavich}}}, \bibinfo {author} {\bibfnamefont {R.~L.}\ \bibnamefont {{Gilliland}}}, \bibinfo {author} {\bibfnamefont {C.~J.}\ \bibnamefont {{Hogan}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Jha}}}, \bibinfo {author} {\bibfnamefont {R.~P.}\ \bibnamefont {{Kirshner}}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {{Leibundgut}}}, \bibinfo {author} {\bibfnamefont {M.~M.}\ \bibnamefont {{Phillips}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Reiss}}}, \bibinfo {author} {\bibfnamefont {B.~P.}\ \bibnamefont {{Schmidt}}}, \bibinfo {author} {\bibfnamefont {R.~A.}\
  \bibnamefont {{Schommer}}}, \bibinfo {author} {\bibfnamefont {R.~C.}\ \bibnamefont {{Smith}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Spyromilio}}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Stubbs}}}, \bibinfo {author} {\bibfnamefont {N.~B.}\ \bibnamefont {{Suntzeff}}},\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Tonry}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Observational Evidence from Supernovae for an Accelerating Universe and a Cosmological Constant}}},\ }\href {https://doi.org/10.1086/300499} {\bibfield  {journal} {\bibinfo  {journal} {AJ}\ }\textbf {\bibinfo {volume} {116}},\ \bibinfo {pages} {1009--1038} (\bibinfo {year} {1998})},\ \Eprint {https://arxiv.org/abs/astro-ph/9805201} {arXiv:astro-ph/9805201 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Abdalla}}\ \emph {et~al.}(2022)\citenamefont {{Abdalla}} \emph {et~al.}}]{Abdalla2022TensionReview}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Abdalla}}} \emph {et~al.},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Cosmology intertwined: A review of the particle physics, astrophysics, and cosmology associated with the cosmological tensions and anomalies}}},\ }\href {https://doi.org/10.1016/j.jheap.2022.04.002} {\bibfield  {journal} {\bibinfo  {journal} {Journal of High Energy Astrophysics}\ }\textbf {\bibinfo {volume} {34}},\ \bibinfo {pages} {49--211} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2203.06142} {arXiv:2203.06142 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Handley}}\ and\ \citenamefont {{Lemos}}(2019)}]{Handley_tensions_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Handley}}}\ and\ \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Lemos}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Quantifying tensions in cosmological parameters: Interpreting the DES evidence ratio}}},\ }\href {https://doi.org/10.1103/PhysRevD.100.043504} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {100}},\ \bibinfo {eid} {043504} (\bibinfo {year} {2019})},\ \Eprint {https://arxiv.org/abs/1902.04029} {arXiv:1902.04029 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Raveri}}\ \emph {et~al.}(2020)\citenamefont {{Raveri}}, \citenamefont {{Zacharegkas}},\ and\ \citenamefont {{Hu}}}]{Raveri2020parameterDifference}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Raveri}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Zacharegkas}}},\ and\ \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Hu}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Quantifying concordance of correlated cosmological data sets}}},\ }\href {https://doi.org/10.1103/PhysRevD.101.103527} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {101}},\ \bibinfo {eid} {103527} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1912.04880} {arXiv:1912.04880 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Raveri}}\ and\ \citenamefont {{Doux}}(2021)}]{Raveri2021ParameterDiff}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Raveri}}}\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Doux}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Non-Gaussian estimates of tensions in cosmological parameters}}},\ }\href {https://doi.org/10.1103/PhysRevD.104.043504} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {104}},\ \bibinfo {eid} {043504} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2105.03324} {arXiv:2105.03324 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Raveri}}\ and\ \citenamefont {{Hu}}(2019)}]{Raveri2019GoFDegredation}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Raveri}}}\ and\ \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Hu}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Concordance and discordance in cosmology}}},\ }\href {https://doi.org/10.1103/PhysRevD.99.043506} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {99}},\ \bibinfo {eid} {043506} (\bibinfo {year} {2019})},\ \Eprint {https://arxiv.org/abs/1806.04649} {arXiv:1806.04649 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Park}}\ and\ \citenamefont {{Rozo}}(2020)}]{Park2020Eigentension}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {{Park}}}\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Rozo}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Concordance cosmology?}}},\ }\href {https://doi.org/10.1093/mnras/staa2647} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {499}},\ \bibinfo {pages} {4638--4645} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1907.05798} {arXiv:1907.05798 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Charnock}}\ \emph {et~al.}(2017)\citenamefont {{Charnock}}, \citenamefont {{Battye}},\ and\ \citenamefont {{Moss}}}]{Charnock_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Charnock}}}, \bibinfo {author} {\bibfnamefont {R.~A.}\ \bibnamefont {{Battye}}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Moss}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Planck data versus large scale structure: Methods to quantify discordance}}},\ }\href {https://doi.org/10.1103/PhysRevD.95.123535} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {95}},\ \bibinfo {eid} {123535} (\bibinfo {year} {2017})},\ \Eprint {https://arxiv.org/abs/1703.05959} {arXiv:1703.05959 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{DES Collaboration}}(2021)}]{Lemos2021DESTensions}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{DES Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Assessing tension metrics with dark energy survey and Planck data}}},\ }\href {https://doi.org/10.1093/mnras/stab1670} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {505}},\ \bibinfo {pages} {6179--6194} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2012.09554} {arXiv:2012.09554 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Saraivanov}}\ \emph {et~al.}(2024)\citenamefont {{Saraivanov}}, \citenamefont {{Zhong}}, \citenamefont {{Miranda}}, \citenamefont {{Boruah}}, \citenamefont {{Eifler}},\ and\ \citenamefont {{Krause}}}]{Saraivanov2024Metrics}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Saraivanov}}}, \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {{Zhong}}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {{Miranda}}}, \bibinfo {author} {\bibfnamefont {S.~S.}\ \bibnamefont {{Boruah}}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Eifler}}},\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Krause}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Attention-Based Neural Network Emulators for Multi-Probe Data Vectors Part II: Assessing Tension Metrics}}},\ }\href {https://doi.org/10.48550/arXiv.2403.12337} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2403.12337}} (\bibinfo {year} {2024})},\ \Eprint {https://arxiv.org/abs/2403.12337} {arXiv:2403.12337 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Marshall}}\ \emph {et~al.}(2006)\citenamefont {{Marshall}}, \citenamefont {{Rajguru}},\ and\ \citenamefont {{Slosar}}}]{Marshall_2006}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Marshall}}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Rajguru}}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Slosar}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Bayesian evidence as a tool for comparing datasets}}},\ }\href {https://doi.org/10.1103/PhysRevD.73.067302} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {73}},\ \bibinfo {eid} {067302} (\bibinfo {year} {2006})},\ \Eprint {https://arxiv.org/abs/astro-ph/0412535} {arXiv:astro-ph/0412535 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Trotta}}(2008)}]{Trotta_2008}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Trotta}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Bayes in the sky: Bayesian inference and model selection in cosmology}}},\ }\href {https://doi.org/10.1080/00107510802066753} {\bibfield  {journal} {\bibinfo  {journal} {Contemporary Physics}\ }\textbf {\bibinfo {volume} {49}},\ \bibinfo {pages} {71--104} (\bibinfo {year} {2008})},\ \Eprint {https://arxiv.org/abs/0803.4089} {arXiv:0803.4089 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Seehars}\ \emph {et~al.}(2016)\citenamefont {Seehars}, \citenamefont {Grandis}, \citenamefont {Amara},\ and\ \citenamefont {Refregier}}]{Seehars_2016}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Seehars}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Grandis}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Amara}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Refregier}},\ }\bibfield  {title} {\emph {\bibinfo {title} {Quantifying concordance in cosmology}},\ }\href {https://doi.org/10.1103/PhysRevD.93.103507} {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. D}\ }\textbf {\bibinfo {volume} {93}},\ \bibinfo {pages} {103507} (\bibinfo {year} {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Cort{\^e}s}}\ and\ \citenamefont {{Liddle}}(2024)}]{Cortes2024Tension}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Cort{\^e}s}}}\ and\ \bibinfo {author} {\bibfnamefont {A.~R.}\ \bibnamefont {{Liddle}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{On data set tensions and signatures of new cosmological physics}}},\ }\href {https://doi.org/10.1093/mnrasl/slae030} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {531}},\ \bibinfo {pages} {L52--L56} (\bibinfo {year} {2024})},\ \Eprint {https://arxiv.org/abs/2309.03286} {arXiv:2309.03286 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Cuceu}}\ \emph {et~al.}(2019)\citenamefont {{Cuceu}}, \citenamefont {{Farr}}, \citenamefont {{Lemos}},\ and\ \citenamefont {{Font-Ribera}}}]{Cuceu2019BAO}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Cuceu}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Farr}}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Lemos}}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Font-Ribera}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Baryon Acoustic Oscillations and the Hubble constant: past, present and future}}},\ }\href {https://doi.org/10.1088/1475-7516/2019/10/044} {\bibfield  {journal} {\bibinfo  {journal} {J.\ Cosmology Astropart.\ Phys.}\ }\textbf {\bibinfo {volume} {2019}},\ \bibinfo {eid} {044} (\bibinfo {year} {2019})},\ \Eprint {https://arxiv.org/abs/1906.11628} {arXiv:1906.11628 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Cranmer}}\ \emph {et~al.}(2020)\citenamefont {{Cranmer}}, \citenamefont {{Brehmer}},\ and\ \citenamefont {{Louppe}}}]{Cranmer202SBI}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {{Cranmer}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Brehmer}}},\ and\ \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Louppe}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The frontier of simulation-based inference}}},\ }\href {https://doi.org/10.1073/pnas.1912789117} {\bibfield  {journal} {\bibinfo  {journal} {Proceedings of the National Academy of Science}\ }\textbf {\bibinfo {volume} {117}},\ \bibinfo {pages} {30055--30062} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1911.01429} {arXiv:1911.01429 [stat.ML]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Miller}}\ \emph {et~al.}(2021)\citenamefont {{Miller}}, \citenamefont {{Cole}}, \citenamefont {{Forr{\'e}}}, \citenamefont {{Louppe}},\ and\ \citenamefont {{Weniger}}}]{Miller2021TMNRE}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {{Miller}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Cole}}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Forr{\'e}}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Louppe}}},\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Weniger}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Truncated Marginal Neural Ratio Estimation}}},\ }\href {https://doi.org/10.48550/arXiv.2107.01214} {\bibfield  {journal} {\bibinfo  {journal} {Advances in Neural Information Processing Systems}\ }\textbf {\bibinfo {volume} {34}},\ \bibinfo {pages} {129} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2107.01214} {arXiv:2107.01214 [stat.ML]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Cole}}\ \emph {et~al.}(2022)\citenamefont {{Cole}}, \citenamefont {{Miller}}, \citenamefont {{Witte}}, \citenamefont {{Cai}}, \citenamefont {{Grootes}}, \citenamefont {{Nattino}},\ and\ \citenamefont {{Weniger}}}]{Cole2022TMNRE}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Cole}}}, \bibinfo {author} {\bibfnamefont {B.~K.}\ \bibnamefont {{Miller}}}, \bibinfo {author} {\bibfnamefont {S.~J.}\ \bibnamefont {{Witte}}}, \bibinfo {author} {\bibfnamefont {M.~X.}\ \bibnamefont {{Cai}}}, \bibinfo {author} {\bibfnamefont {M.~W.}\ \bibnamefont {{Grootes}}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {{Nattino}}},\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Weniger}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Fast and credible likelihood-free cosmology with truncated marginal neural ratio estimation}}},\ }\href {https://doi.org/10.1088/1475-7516/2022/09/004} {\bibfield  {journal} {\bibinfo  {journal} {J.\ Cosmology Astropart.\ Phys.}\ }\textbf {\bibinfo {volume} {2022}},\ \bibinfo {eid} {004} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2111.08030} {arXiv:2111.08030 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Skilling}(2006)}]{skilling_ns_2006}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Skilling}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Nested sampling for general Bayesian computation}}},\ }\href {https://doi.org/10.1214/06-BA127} {\bibfield  {journal} {\bibinfo  {journal} {Bayesian Analysis}\ }\textbf {\bibinfo {volume} {1}},\ \bibinfo {pages} {833 -- 859} (\bibinfo {year} {2006})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Ashton}}\ \emph {et~al.}(2022)\citenamefont {{Ashton}}, \citenamefont {{Bernstein}}, \citenamefont {{Buchner}}, \citenamefont {{Chen}}, \citenamefont {{Cs{\'a}nyi}}, \citenamefont {{Fowlie}}, \citenamefont {{Feroz}}, \citenamefont {{Griffiths}}, \citenamefont {{Handley}}, \citenamefont {{Habeck}}, \citenamefont {{Higson}}, \citenamefont {{Hobson}}, \citenamefont {{Lasenby}}, \citenamefont {{Parkinson}}, \citenamefont {{P{\'a}rtay}}, \citenamefont {{Pitkin}}, \citenamefont {{Schneider}}, \citenamefont {{Speagle}}, \citenamefont {{South}}, \citenamefont {{Veitch}}, \citenamefont {{Wacker}}, \citenamefont {{Wales}},\ and\ \citenamefont {{Yallup}}}]{Ashton_NS_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Ashton}}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Bernstein}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Buchner}}}, \bibinfo {author} {\bibfnamefont {X.}~\bibnamefont {{Chen}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Cs{\'a}nyi}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fowlie}}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {{Feroz}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Griffiths}}}, \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Habeck}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Higson}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Hobson}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Lasenby}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Parkinson}}}, \bibinfo {author} {\bibfnamefont {L.~B.}\ \bibnamefont {{P{\'a}rtay}}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {{Pitkin}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Schneider}}}, \bibinfo {author} {\bibfnamefont {J.~S.}\ \bibnamefont {{Speagle}}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {{South}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Veitch}}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {{Wacker}}}, \bibinfo {author} {\bibfnamefont {D.~J.}\ \bibnamefont {{Wales}}},\ and\ \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Yallup}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Nested sampling for physical scientists}}},\ }\href {https://doi.org/10.1038/s43586-022-00121-x} {\bibfield  {journal} {\bibinfo  {journal} {Nature Reviews Methods Primers}\ }\textbf {\bibinfo {volume} {2}},\ \bibinfo {eid} {39} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2205.15570} {arXiv:2205.15570 [stat.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Trotta}}(2007)}]{Trotta_2007}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Trotta}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Applications of Bayesian model selection to cosmological parameters}}},\ }\href {https://doi.org/10.1111/j.1365-2966.2007.11738.x} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {378}},\ \bibinfo {pages} {72--82} (\bibinfo {year} {2007})},\ \Eprint {https://arxiv.org/abs/astro-ph/0504022} {arXiv:astro-ph/0504022 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Heavens}}\ \emph {et~al.}(2017)\citenamefont {{Heavens}}, \citenamefont {{Fantaye}}, \citenamefont {{Mootoovaloo}}, \citenamefont {{Eggers}}, \citenamefont {{Hosenie}}, \citenamefont {{Kroon}},\ and\ \citenamefont {{Sellentin}}}]{Heavens_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Heavens}}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {{Fantaye}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Mootoovaloo}}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {{Eggers}}}, \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {{Hosenie}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Kroon}}},\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Sellentin}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Marginal Likelihoods from Monte Carlo Markov Chains}}},\ }\href {https://doi.org/10.48550/arXiv.1704.03472} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:1704.03472}} (\bibinfo {year} {2017})},\ \Eprint {https://arxiv.org/abs/1704.03472} {arXiv:1704.03472 [stat.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Srinivasan}}\ \emph {et~al.}(2024)\citenamefont {{Srinivasan}}, \citenamefont {{Crisostomi}}, \citenamefont {{Trotta}}, \citenamefont {{Barausse}},\ and\ \citenamefont {{Breschi}}}]{Srinivasan2024floZ}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Srinivasan}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Crisostomi}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Trotta}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Barausse}}},\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Breschi}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{floZ: Evidence estimation from posterior samples with normalizing flows}}},\ }\href {https://doi.org/10.48550/arXiv.2404.12294} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2404.12294}} (\bibinfo {year} {2024})},\ \Eprint {https://arxiv.org/abs/2404.12294} {arXiv:2404.12294 [stat.ML]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Foreman-Mackey}}\ \emph {et~al.}(2013)\citenamefont {{Foreman-Mackey}}, \citenamefont {{Hogg}}, \citenamefont {{Lang}},\ and\ \citenamefont {{Goodman}}}]{emcee}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Foreman-Mackey}}}, \bibinfo {author} {\bibfnamefont {D.~W.}\ \bibnamefont {{Hogg}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Lang}}},\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Goodman}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{emcee: The MCMC Hammer}}},\ }\href {https://doi.org/10.1086/670067} {\bibfield  {journal} {\bibinfo  {journal} {PASP}\ }\textbf {\bibinfo {volume} {125}},\ \bibinfo {pages} {306} (\bibinfo {year} {2013})},\ \Eprint {https://arxiv.org/abs/1202.3665} {arXiv:1202.3665 [astro-ph.IM]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Polanska}}\ \emph {et~al.}(2023)\citenamefont {{Polanska}}, \citenamefont {{Price}}, \citenamefont {{Spurio Mancini}},\ and\ \citenamefont {{McEwen}}}]{Polanska2023harmonicmean}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Polanska}}}, \bibinfo {author} {\bibfnamefont {M.~A.}\ \bibnamefont {{Price}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Spurio Mancini}}},\ and\ \bibinfo {author} {\bibfnamefont {J.~D.}\ \bibnamefont {{McEwen}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Learned harmonic mean estimation of the marginal likelihood with normalizing flows}}},\ }\href {https://doi.org/10.48550/arXiv.2307.00048} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2307.00048}} (\bibinfo {year} {2023})},\ \Eprint {https://arxiv.org/abs/2307.00048} {arXiv:2307.00048 [stat.ME]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Dark Energy Survey Collaboration}}(2018)}]{DES_Y1}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{Dark Energy Survey Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Dark Energy Survey year 1 results: Cosmological constraints from galaxy clustering and weak lensing}}},\ }\href {https://doi.org/10.1103/PhysRevD.98.043526} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {98}},\ \bibinfo {eid} {043526} (\bibinfo {year} {2018})},\ \Eprint {https://arxiv.org/abs/1708.01530} {arXiv:1708.01530 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Jeffreys}(1983)}]{jeffreys1983theory}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Jeffreys}},\ }\href {https://books.google.co.uk/books?id=EbodAQAAMAAJ} {\emph {\bibinfo {title} {Theory of Probability}}},\ International series of monographs on physics\ (\bibinfo  {publisher} {Clarendon Press},\ \bibinfo {year} {1983})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Furlanetto}}\ \emph {et~al.}(2006)\citenamefont {{Furlanetto}}, \citenamefont {{Oh}},\ and\ \citenamefont {{Briggs}}}]{Furlanetto2006}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.~R.}\ \bibnamefont {{Furlanetto}}}, \bibinfo {author} {\bibfnamefont {S.~P.}\ \bibnamefont {{Oh}}},\ and\ \bibinfo {author} {\bibfnamefont {F.~H.}\ \bibnamefont {{Briggs}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Cosmology at low frequencies: The 21 cm transition and the high-redshift Universe}}},\ }\href {https://doi.org/10.1016/j.physrep.2006.08.002} {\bibfield  {journal} {\bibinfo  {journal} {Phys.\ Rep.}\ }\textbf {\bibinfo {volume} {433}},\ \bibinfo {pages} {181--301} (\bibinfo {year} {2006})},\ \Eprint {https://arxiv.org/abs/astro-ph/0608032} {arXiv:astro-ph/0608032 [astro-ph]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Barkana}}(2016)}]{Barkana2016}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The rise of the first stars: Supersonic streaming, radiative feedback, and 21-cm cosmology}}},\ }\href {https://doi.org/10.1016/j.physrep.2016.06.006} {\bibfield  {journal} {\bibinfo  {journal} {Phys.\ Rep.}\ }\textbf {\bibinfo {volume} {645}},\ \bibinfo {pages} {1--59} (\bibinfo {year} {2016})},\ \Eprint {https://arxiv.org/abs/1605.04357} {arXiv:1605.04357 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Mesinger}(2019)}]{Mesinger2019}%
  \BibitemOpen
  \bibinfo {editor} {\bibfnamefont {A.}~\bibnamefont {Mesinger}},\ ed.,\ \href {https://doi.org/10.1088/2514-3433/ab4a73} {\emph {\bibinfo {title} {The Cosmic 21-cm Revolution}}},\ 2514-3433\ (\bibinfo  {publisher} {IOP Publishing},\ \bibinfo {year} {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Liu}}\ and\ \citenamefont {{Shaw}}(2020)}]{Liu2020}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Liu}}}\ and\ \bibinfo {author} {\bibfnamefont {J.~R.}\ \bibnamefont {{Shaw}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Data Analysis for Precision 21 cm Cosmology}}},\ }\href {https://doi.org/10.1088/1538-3873/ab5bfd} {\bibfield  {journal} {\bibinfo  {journal} {PASP}\ }\textbf {\bibinfo {volume} {132}},\ \bibinfo {eid} {062001} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1907.08211} {arXiv:1907.08211 [astro-ph.IM]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Bowman}}\ \emph {et~al.}(2018)\citenamefont {{Bowman}}, \citenamefont {{Rogers}}, \citenamefont {{Monsalve}}, \citenamefont {{Mozdzen}},\ and\ \citenamefont {{Mahesh}}}]{EDGES}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~D.}\ \bibnamefont {{Bowman}}}, \bibinfo {author} {\bibfnamefont {A.~E.~E.}\ \bibnamefont {{Rogers}}}, \bibinfo {author} {\bibfnamefont {R.~A.}\ \bibnamefont {{Monsalve}}}, \bibinfo {author} {\bibfnamefont {T.~J.}\ \bibnamefont {{Mozdzen}}},\ and\ \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Mahesh}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{An absorption profile centred at 78 megahertz in the sky-averaged spectrum}}},\ }\href {https://doi.org/10.1038/nature25792} {\bibfield  {journal} {\bibinfo  {journal} {\nat}\ }\textbf {\bibinfo {volume} {555}},\ \bibinfo {pages} {67--70} (\bibinfo {year} {2018})},\ \Eprint {https://arxiv.org/abs/1810.05912} {arXiv:1810.05912 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Singh}}\ \emph {et~al.}(2022{\natexlab{b}})\citenamefont {{Singh}}, \citenamefont {{Jishnu}}, \citenamefont {{Subrahmanyan}}, \citenamefont {{Udaya Shankar}}, \citenamefont {{Girish}}, \citenamefont {{Raghunathan}}, \citenamefont {{Somashekar}}, \citenamefont {{Srivani}},\ and\ \citenamefont {{Sathyanarayana Rao}}}]{SARAS3}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Singh}}}, \bibinfo {author} {\bibfnamefont {N.~T.}\ \bibnamefont {{Jishnu}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Subrahmanyan}}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Udaya Shankar}}}, \bibinfo {author} {\bibfnamefont {B.~S.}\ \bibnamefont {{Girish}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Raghunathan}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Somashekar}}}, \bibinfo {author} {\bibfnamefont {K.~S.}\ \bibnamefont {{Srivani}}},\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Sathyanarayana Rao}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{On the detection of a cosmic dawn signal in the radio background}}},\ }\href {https://doi.org/10.1038/s41550-022-01610-5} {\bibfield  {journal} {\bibinfo  {journal} {Nature Astronomy}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {pages} {607--617} (\bibinfo {year} {2022}{\natexlab{b}})},\ \Eprint
  {https://arxiv.org/abs/2112.06778} {arXiv:2112.06778 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{de Lera Acedo}}\ \emph {et~al.}(2022)\citenamefont {{de Lera Acedo}}, \citenamefont {{de Villiers}}, \citenamefont {{Razavi-Ghods}}, \citenamefont {{Handley}}, \citenamefont {{Fialkov}}, \citenamefont {{Magro}}, \citenamefont {{Anstey}}, \citenamefont {{Bevins}}, \citenamefont {{Chiello}}, \citenamefont {{Cumner}}, \citenamefont {{Josaitis}}, \citenamefont {{Roque}}, \citenamefont {{Sims}}, \citenamefont {{Scheutwinkel}}, \citenamefont {{Alexander}}, \citenamefont {{Bernardi}}, \citenamefont {{Carey}}, \citenamefont {{Cavillot}}, \citenamefont {{Croukamp}}, \citenamefont {{Ely}}, \citenamefont {{Gessey-Jones}}, \citenamefont {{Gueuning}}, \citenamefont {{Hills}}, \citenamefont {{Kulkarni}}, \citenamefont {{Maiolino}}, \citenamefont {{Meerburg}}, \citenamefont {{Mittal}}, \citenamefont {{Pritchard}}, \citenamefont {{Puchwein}}, \citenamefont {{Saxena}}, \citenamefont {{Shen}}, \citenamefont {{Smirnov}}, \citenamefont {{Spinelli}},\ and\ \citenamefont {{Zarb-Adami}}}]{Acedo2022REACH}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}}, \bibinfo {author} {\bibfnamefont {D.~I.~L.}\ \bibnamefont {{de Villiers}}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {{Razavi-Ghods}}}, \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Magro}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Anstey}}}, \bibinfo {author} {\bibfnamefont {H.~T.~J.}\ \bibnamefont {{Bevins}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Chiello}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Cumner}}}, \bibinfo {author} {\bibfnamefont {A.~T.}\ \bibnamefont {{Josaitis}}}, \bibinfo {author} {\bibfnamefont {I.~L.~V.}\ \bibnamefont {{Roque}}}, \bibinfo {author} {\bibfnamefont {P.~H.}\ \bibnamefont {{Sims}}}, \bibinfo {author} {\bibfnamefont {K.~H.}\ \bibnamefont {{Scheutwinkel}}}, \bibinfo {author} {\bibfnamefont
  {P.}~\bibnamefont {{Alexander}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Bernardi}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Carey}}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {{Cavillot}}}, \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Croukamp}}}, \bibinfo {author} {\bibfnamefont {J.~A.}\ \bibnamefont {{Ely}}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Gessey-Jones}}}, \bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont {{Gueuning}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Hills}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Kulkarni}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Maiolino}}}, \bibinfo {author} {\bibfnamefont {P.~D.}\ \bibnamefont {{Meerburg}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Mittal}}}, \bibinfo {author} {\bibfnamefont {J.~R.}\ \bibnamefont {{Pritchard}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Puchwein}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {{Saxena}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Shen}}}, \bibinfo {author} {\bibfnamefont {O.}~\bibnamefont {{Smirnov}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Spinelli}}},\ and\ \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {{Zarb-Adami}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The REACH radiometer for detecting the 21-cm hydrogen signal from redshift z {\ensuremath{\approx}} 7.5-28}}},\ }\href {https://doi.org/10.1038/s41550-022-01709-9} {\bibfield  {journal} {\bibinfo  {journal} {Nature Astronomy}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo {pages} {984--998} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2210.07409} {arXiv:2210.07409 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Mirocha}(2014)}]{Mirocha2014ARES}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Mirocha}},\ }\bibfield  {title} {\emph {\bibinfo {title} {Decoding the x-ray properties of pre-reionization era sources}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {443}},\ \bibinfo {pages} {1211--1223} (\bibinfo {year} {2014})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Mesinger}\ \emph {et~al.}(2011)\citenamefont {Mesinger}, \citenamefont {Furlanetto},\ and\ \citenamefont {Cen}}]{Mesinger201121cmfast}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Mesinger}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Furlanetto}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Cen}},\ }\bibfield  {title} {\emph {\bibinfo {title} {21cmfast: a fast, seminumerical simulation of the high-redshift 21-cm signal}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {411}},\ \bibinfo {pages} {955--972} (\bibinfo {year} {2011})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Reis}}\ \emph {et~al.}(2020)\citenamefont {{Reis}}, \citenamefont {{Fialkov}},\ and\ \citenamefont {{Barkana}}}]{Reis2020radioGalaxies}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {{Reis}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{High-redshift radio galaxies: a potential new source of 21-cm fluctuations}}},\ }\href {https://doi.org/10.1093/mnras/staa3091} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {499}},\ \bibinfo {pages} {5993--6008} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/2008.04315} {arXiv:2008.04315 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Reis}}\ \emph {et~al.}(2021)\citenamefont {{Reis}}, \citenamefont {{Fialkov}},\ and\ \citenamefont {{Barkana}}}]{Reis2021Lyalpha}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {{Reis}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The subtlety of Ly {\ensuremath{\alpha}} photons: changing the expected range of the 21-cm signal}}},\ }\href {https://doi.org/10.1093/mnras/stab2089} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {506}},\ \bibinfo {pages} {5479--5493} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2101.01777} {arXiv:2101.01777 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Gessey-Jones}}\ \emph {et~al.}(2022)\citenamefont {{Gessey-Jones}}, \citenamefont {{Sartorio}}, \citenamefont {{Fialkov}}, \citenamefont {{Mirouh}}, \citenamefont {{Magg}}, \citenamefont {{Izzard}}, \citenamefont {{de Lera Acedo}}, \citenamefont {{Handley}},\ and\ \citenamefont {{Barkana}}}]{GesseyJones2022IMF}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Gessey-Jones}}}, \bibinfo {author} {\bibfnamefont {N.~S.}\ \bibnamefont {{Sartorio}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}}, \bibinfo {author} {\bibfnamefont {G.~M.}\ \bibnamefont {{Mirouh}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Magg}}}, \bibinfo {author} {\bibfnamefont {R.~G.}\ \bibnamefont {{Izzard}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}}, \bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Handley}}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Impact of the primordial stellar initial mass function on the 21-cm signal}}},\ }\href {https://doi.org/10.1093/mnras/stac2049} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {516}},\ \bibinfo {pages} {841--860} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/2202.02099} {arXiv:2202.02099
  [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Sikder}}\ \emph {et~al.}(2024)\citenamefont {{Sikder}}, \citenamefont {{Barkana}}, \citenamefont {{Fialkov}},\ and\ \citenamefont {{Reis}}}]{Skider2024LineSight}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Sikder}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}},\ and\ \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {{Reis}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Strong 21-cm fluctuations and anisotropy due to the line-of-sight effect of radio galaxies at cosmic dawn}}},\ }\href {https://doi.org/10.1093/mnras/stad3847} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {527}},\ \bibinfo {pages} {10975--10985} (\bibinfo {year} {2024})},\ \Eprint {https://arxiv.org/abs/2301.04585} {arXiv:2301.04585 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Pochinda}}\ \emph {et~al.}(2024)\citenamefont {{Pochinda}}, \citenamefont {{Gessey-Jones}}, \citenamefont {{Bevins}}, \citenamefont {{Fialkov}}, \citenamefont {{Heimersheim}}, \citenamefont {{Abril-Cabezas}}, \citenamefont {{de Lera Acedo}}, \citenamefont {{Singh}}, \citenamefont {{Sikder}},\ and\ \citenamefont {{Barkana}}}]{Pochinda2023Joint}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Pochinda}}}, \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Gessey-Jones}}}, \bibinfo {author} {\bibfnamefont {H.~T.~J.}\ \bibnamefont {{Bevins}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Heimersheim}}}, \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {{Abril-Cabezas}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Singh}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Sikder}}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Constraining the properties of Population III galaxies with multiwavelength observations}}},\ }\href {https://doi.org/10.1093/mnras/stae1185} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {531}},\ \bibinfo {pages} {1113--1132} (\bibinfo
  {year} {2024})},\ \Eprint {https://arxiv.org/abs/2312.08095} {arXiv:2312.08095 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Gessey-Jones}}\ \emph {et~al.}(2024)\citenamefont {{Gessey-Jones}}, \citenamefont {{Pochinda}}, \citenamefont {{Bevins}}, \citenamefont {{Fialkov}}, \citenamefont {{Handley}}, \citenamefont {{de Lera Acedo}}, \citenamefont {{Singh}},\ and\ \citenamefont {{Barkana}}}]{GesseyJones2024Joint}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {T.}~\bibnamefont {{Gessey-Jones}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Pochinda}}}, \bibinfo {author} {\bibfnamefont {H.~T.~J.}\ \bibnamefont {{Bevins}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}}, \bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Singh}}},\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Barkana}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{On the constraints on superconducting cosmic strings from 21-cm cosmology}}},\ }\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\href {https://doi.org/10.1093/mnras/stae512} {10.1093/mnras/stae512} (\bibinfo {year} {2024}),\ \Eprint {https://arxiv.org/abs/2312.08828} {arXiv:2312.08828 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Mu{\~n}oz}(2023)}]{Munoz2023Zeus}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~B.}\ \bibnamefont {Mu{\~n}oz}},\ }\bibfield  {title} {\emph {\bibinfo {title} {An effective model for the cosmic-dawn 21-cm signal}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {523}},\ \bibinfo {pages} {2587--2607} (\bibinfo {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Anstey}}\ \emph {et~al.}(2021)\citenamefont {{Anstey}}, \citenamefont {{de Lera Acedo}},\ and\ \citenamefont {{Handley}}}]{Anstey2021REACH}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Anstey}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}},\ and\ \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {{Handley}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{A general Bayesian framework for foreground modelling and chromaticity correction for global 21 cm experiments}}},\ }\href {https://doi.org/10.1093/mnras/stab1765} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {506}},\ \bibinfo {pages} {2041--2058} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2010.09644} {arXiv:2010.09644 [astro-ph.IM]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Hills}}\ \emph {et~al.}(2018)\citenamefont {{Hills}}, \citenamefont {{Kulkarni}}, \citenamefont {{Meerburg}},\ and\ \citenamefont {{Puchwein}}}]{Hills2018Edges}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Hills}}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {{Kulkarni}}}, \bibinfo {author} {\bibfnamefont {P.~D.}\ \bibnamefont {{Meerburg}}},\ and\ \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Puchwein}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Concerns about modelling of the EDGES data}}},\ }\href {https://doi.org/10.1038/s41586-018-0796-5} {\bibfield  {journal} {\bibinfo  {journal} {Nature}\ }\textbf {\bibinfo {volume} {564}},\ \bibinfo {pages} {E32--E34} (\bibinfo {year} {2018})},\ \Eprint {https://arxiv.org/abs/1805.01421} {arXiv:1805.01421 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Singh}}\ and\ \citenamefont {{Subrahmanyan}}(2019)}]{Singh2019EDGES}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Singh}}}\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Subrahmanyan}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The Redshifted 21 cm Signal in the EDGES Low-band Spectrum}}},\ }\href {https://doi.org/10.3847/1538-4357/ab2879} {\bibfield  {journal} {\bibinfo  {journal} {ApJ}\ }\textbf {\bibinfo {volume} {880}},\ \bibinfo {eid} {26} (\bibinfo {year} {2019})},\ \Eprint {https://arxiv.org/abs/1903.04540} {arXiv:1903.04540 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Sims}}\ and\ \citenamefont {{Pober}}(2020)}]{Sims2020EDGES}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.~H.}\ \bibnamefont {{Sims}}}\ and\ \bibinfo {author} {\bibfnamefont {J.~C.}\ \bibnamefont {{Pober}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Testing for calibration systematics in the EDGES low-band data using Bayesian model selection}}},\ }\href {https://doi.org/10.1093/mnras/stz3388} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {492}},\ \bibinfo {pages} {22--38} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1910.03165} {arXiv:1910.03165 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Bevins}}\ \emph {et~al.}(2021)\citenamefont {{Bevins}}, \citenamefont {{Handley}}, \citenamefont {{Fialkov}}, \citenamefont {{de Lera Acedo}}, \citenamefont {{Greenhill}},\ and\ \citenamefont {{Price}}}]{Bevins2021maxsmooth}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.~T.~J.}\ \bibnamefont {{Bevins}}}, \bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Fialkov}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{de Lera Acedo}}}, \bibinfo {author} {\bibfnamefont {L.~J.}\ \bibnamefont {{Greenhill}}},\ and\ \bibinfo {author} {\bibfnamefont {D.~C.}\ \bibnamefont {{Price}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{MAXSMOOTH: rapid maximally smooth function fitting with applications in Global 21-cm cosmology}}},\ }\href {https://doi.org/10.1093/mnras/stab152} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {502}},\ \bibinfo {pages} {4405--4425} (\bibinfo {year} {2021})},\ \Eprint {https://arxiv.org/abs/2007.14970} {arXiv:2007.14970 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Handley}}\ \emph {et~al.}(2015{\natexlab{a}})\citenamefont {{Handley}}, \citenamefont {{Hobson}},\ and\ \citenamefont {{Lasenby}}}]{Handley2015polychorda}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {M.~P.}\ \bibnamefont {{Hobson}}},\ and\ \bibinfo {author} {\bibfnamefont {A.~N.}\ \bibnamefont {{Lasenby}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{POLYCHORD: next-generation nested sampling}}},\ }\href {https://doi.org/10.1093/mnras/stv1911} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {453}},\ \bibinfo {pages} {4384--4398} (\bibinfo {year} {2015}{\natexlab{a}})},\ \Eprint {https://arxiv.org/abs/1506.00171} {arXiv:1506.00171 [astro-ph.IM]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Handley}}\ \emph {et~al.}(2015{\natexlab{b}})\citenamefont {{Handley}}, \citenamefont {{Hobson}},\ and\ \citenamefont {{Lasenby}}}]{Handley2015polychordb}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.~J.}\ \bibnamefont {{Handley}}}, \bibinfo {author} {\bibfnamefont {M.~P.}\ \bibnamefont {{Hobson}}},\ and\ \bibinfo {author} {\bibfnamefont {A.~N.}\ \bibnamefont {{Lasenby}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{polychord: nested sampling for cosmology.}}},\ }\href {https://doi.org/10.1093/mnrasl/slv047} {\bibfield  {journal} {\bibinfo  {journal} {Monthly Notices of the Royal Astronomical Society}\ }\textbf {\bibinfo {volume} {450}},\ \bibinfo {pages} {L61--L65} (\bibinfo {year} {2015}{\natexlab{b}})},\ \Eprint {https://arxiv.org/abs/1502.01856} {arXiv:1502.01856 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Alam}}\ \emph {et~al.}(2015)\citenamefont {{Alam}} \emph {et~al.}}]{Alam2015SDSSDR12}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Alam}}} \emph {et~al.},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The Eleventh and Twelfth Data Releases of the Sloan Digital Sky Survey: Final Data from SDSS-III}}},\ }\href {https://doi.org/10.1088/0067-0049/219/1/12} {\bibfield  {journal} {\bibinfo  {journal} {ApJS}\ }\textbf {\bibinfo {volume} {219}},\ \bibinfo {eid} {12} (\bibinfo {year} {2015})},\ \Eprint {https://arxiv.org/abs/1501.00963} {arXiv:1501.00963 [astro-ph.IM]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Ahumada}}\ \emph {et~al.}(2020)\citenamefont {{Ahumada}} \emph {et~al.}}]{Ahumada2020SDSSDR16}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Ahumada}}} \emph {et~al.},\ }\bibfield  {title} {\emph {\bibinfo {title} {{The 16th Data Release of the Sloan Digital Sky Surveys: First Release from the APOGEE-2 Southern Survey and Full Release of eBOSS Spectra}}},\ }\href {https://doi.org/10.3847/1538-4365/ab929e} {\bibfield  {journal} {\bibinfo  {journal} {ApJS}\ }\textbf {\bibinfo {volume} {249}},\ \bibinfo {eid} {3} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1912.02905} {arXiv:1912.02905 [astro-ph.GA]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Adame}\ \emph {et~al.}(2024)\citenamefont {Adame}, \citenamefont {Aguilar}, \citenamefont {Ahlen}, \citenamefont {Alam}, \citenamefont {Alexander}, \citenamefont {Alvarez}, \citenamefont {Alves}, \citenamefont {Anand}, \citenamefont {Andrade}, \citenamefont {Armengaud} \emph {et~al.}}]{adame2024desiCosmologyBAO}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Adame}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Aguilar}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Ahlen}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Alam}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Alexander}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Alvarez}}, \bibinfo {author} {\bibfnamefont {O.}~\bibnamefont {Alves}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Anand}}, \bibinfo {author} {\bibfnamefont {U.}~\bibnamefont {Andrade}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Armengaud}}, \emph {et~al.},\ }\bibfield  {title} {\emph {\bibinfo {title} {Desi 2024 vi: Cosmological constraints from the measurements of baryon acoustic oscillations}},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {arXiv preprint arXiv:2404.03002}\ } (\bibinfo {year} {2024})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Bassett}}\ and\ \citenamefont {{Hlozek}}(2010)}]{Bassett2010BAO}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {{Bassett}}}\ and\ \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Hlozek}}},\ }in\ \href {https://doi.org/10.48550/arXiv.0910.5224} {\emph {\bibinfo {booktitle} {Dark Energy: Observational and Theoretical Approaches}}},\ \bibinfo {editor} {edited by\ \bibinfo {editor} {\bibfnamefont {P.}~\bibnamefont {{Ruiz-Lapuente}}}}\ (\bibinfo {year} {2010})\ p.\ \bibinfo {pages} {246}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lewis}\ \emph {et~al.}(2000)\citenamefont {Lewis}, \citenamefont {Challinor},\ and\ \citenamefont {Lasenby}}]{Lewis1999CAMB}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Lewis}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Challinor}},\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Lasenby}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Efficient computation of CMB anisotropies in closed FRW models}}},\ }\href {https://doi.org/10.1086/309179} {\bibfield  {journal} {\bibinfo  {journal} {ApJ}\ }\textbf {\bibinfo {volume} {538}},\ \bibinfo {pages} {473--476} (\bibinfo {year} {2000})},\ \Eprint {https://arxiv.org/abs/astro-ph/9911177} {arXiv:astro-ph/9911177 [astro-ph]} \BibitemShut {NoStop}%
%%CITATION = ASTRO-PH/9911177;%%
\bibitem [{\citenamefont {Lewis}\ and\ \citenamefont {Bridle}(2002)}]{Lewis2002CAMB}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Lewis}}\ and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Bridle}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Cosmological parameters from CMB and other data: A Monte Carlo approach}}},\ }\href {https://doi.org/10.1103/PhysRevD.66.103511} {\bibfield  {journal} {\bibinfo  {journal} {\prd}\ }\textbf {\bibinfo {volume} {66}},\ \bibinfo {pages} {103511} (\bibinfo {year} {2002})},\ \Eprint {https://arxiv.org/abs/astro-ph/0205436} {arXiv:astro-ph/0205436 [astro-ph]} \BibitemShut {NoStop}%
%%CITATION = ASTRO-PH/0205436;%%
\bibitem [{\citenamefont {{DESI Collaboration}}(2024{\natexlab{a}})}]{adame2024desiLyaBAO}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{DESI Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{DESI 2024 IV: Baryon Acoustic Oscillations from the Lyman Alpha Forest}}},\ }\href {https://doi.org/10.48550/arXiv.2404.03001} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2404.03001}} (\bibinfo {year} {2024}{\natexlab{a}})},\ \Eprint {https://arxiv.org/abs/2404.03001} {arXiv:2404.03001 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{DESI Collaboration}}(2024{\natexlab{b}})}]{adame2024desiTension}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{DESI Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{DESI 2024 III: Baryon Acoustic Oscillations from Galaxies and Quasars}}},\ }\href {https://doi.org/10.48550/arXiv.2404.03000} {\bibfield  {journal} {\bibinfo  {journal} {arXiv e-prints}\ ,\ \bibinfo {eid} {arXiv:2404.03000}} (\bibinfo {year} {2024}{\natexlab{b}})},\ \Eprint {https://arxiv.org/abs/2404.03000} {arXiv:2404.03000 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Planck Collaboration}}(2020)}]{Planck2018}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{Planck Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{Planck 2018 results. VI. Cosmological parameters}}},\ }\href {https://doi.org/10.1051/0004-6361/201833910} {\bibfield  {journal} {\bibinfo  {journal} {A\&A}\ }\textbf {\bibinfo {volume} {641}},\ \bibinfo {eid} {A6} (\bibinfo {year} {2020})},\ \Eprint {https://arxiv.org/abs/1807.06209} {arXiv:1807.06209 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Watts}}\ \emph {et~al.}(2023)\citenamefont {{Watts}}, \citenamefont {{Basyrov}}, \citenamefont {{Eskilt}}, \citenamefont {{Galloway}}, \citenamefont {{Gjerl{\o}w}}, \citenamefont {{Hergt}}, \citenamefont {{Herman}}, \citenamefont {{Ihle}}, \citenamefont {{Paradiso}}, \citenamefont {{Rahman}}, \citenamefont {{Thommesen}}, \citenamefont {{Aurlien}}, \citenamefont {{Bersanelli}}, \citenamefont {{Bianchi}}, \citenamefont {{Brilenkov}}, \citenamefont {{Colombo}}, \citenamefont {{Eriksen}}, \citenamefont {{Franceschet}}, \citenamefont {{Fuskeland}}, \citenamefont {{Hensley}}, \citenamefont {{Hoerning}}, \citenamefont {{Lee}}, \citenamefont {{Lunde}}, \citenamefont {{Marins}}, \citenamefont {{Nerval}}, \citenamefont {{Patel}}, \citenamefont {{Regnier}}, \citenamefont {{San}}, \citenamefont {{Sanyal}}, \citenamefont {{Stutzer}}, \citenamefont {{Verma}}, \citenamefont {{Wehus}},\ and\ \citenamefont {{Zhou}}}]{Watts2023Cosmoglobe}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~J.}\ \bibnamefont {{Watts}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Basyrov}}}, \bibinfo {author} {\bibfnamefont {J.~R.}\ \bibnamefont {{Eskilt}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Galloway}}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {{Gjerl{\o}w}}}, \bibinfo {author} {\bibfnamefont {L.~T.}\ \bibnamefont {{Hergt}}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {{Herman}}}, \bibinfo {author} {\bibfnamefont {H.~T.}\ \bibnamefont {{Ihle}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Paradiso}}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {{Rahman}}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {{Thommesen}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Aurlien}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Bersanelli}}}, \bibinfo {author} {\bibfnamefont {L.~A.}\ \bibnamefont {{Bianchi}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Brilenkov}}},
  \bibinfo {author} {\bibfnamefont {L.~P.~L.}\ \bibnamefont {{Colombo}}}, \bibinfo {author} {\bibfnamefont {H.~K.}\ \bibnamefont {{Eriksen}}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Franceschet}}}, \bibinfo {author} {\bibfnamefont {U.}~\bibnamefont {{Fuskeland}}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {{Hensley}}}, \bibinfo {author} {\bibfnamefont {G.~A.}\ \bibnamefont {{Hoerning}}}, \bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {{Lee}}}, \bibinfo {author} {\bibfnamefont {J.~G.~S.}\ \bibnamefont {{Lunde}}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {{Marins}}}, \bibinfo {author} {\bibfnamefont {S.~K.}\ \bibnamefont {{Nerval}}}, \bibinfo {author} {\bibfnamefont {S.~K.}\ \bibnamefont {{Patel}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Regnier}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{San}}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {{Sanyal}}}, \bibinfo {author} {\bibfnamefont {N.~O.}\ \bibnamefont {{Stutzer}}}, \bibinfo {author}
  {\bibfnamefont {A.}~\bibnamefont {{Verma}}}, \bibinfo {author} {\bibfnamefont {I.~K.}\ \bibnamefont {{Wehus}}},\ and\ \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {{Zhou}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{COSMOGLOBE DR1 results. I. Improved Wilkinson Microwave Anisotropy Probe maps through Bayesian end-to-end analysis}}},\ }\href {https://doi.org/10.1051/0004-6361/202346414} {\bibfield  {journal} {\bibinfo  {journal} {A\&A}\ }\textbf {\bibinfo {volume} {679}},\ \bibinfo {eid} {A143} (\bibinfo {year} {2023})},\ \Eprint {https://arxiv.org/abs/2303.08095} {arXiv:2303.08095 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {{Karchev}}\ \emph {et~al.}(2024)\citenamefont {{Karchev}}, \citenamefont {{Grayling}}, \citenamefont {{Boyd}}, \citenamefont {{Trotta}}, \citenamefont {{Mandel}},\ and\ \citenamefont {{Weniger}}}]{Karchev2024supernova}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {K.}~\bibnamefont {{Karchev}}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {{Grayling}}}, \bibinfo {author} {\bibfnamefont {B.~M.}\ \bibnamefont {{Boyd}}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {{Trotta}}}, \bibinfo {author} {\bibfnamefont {K.~S.}\ \bibnamefont {{Mandel}}},\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {{Weniger}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {{SIDE-real: Supernova Ia Dust Extinction with truncated marginal neural ratio estimation applied to real data}}},\ }\href {https://doi.org/10.1093/mnras/stae995} {\bibfield  {journal} {\bibinfo  {journal} {MNRAS}\ }\textbf {\bibinfo {volume} {530}},\ \bibinfo {pages} {3881--3896} (\bibinfo {year} {2024})},\ \Eprint {https://arxiv.org/abs/2403.07871} {arXiv:2403.07871 [astro-ph.CO]} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lemos}\ \emph {et~al.}(2023)\citenamefont {Lemos}, \citenamefont {Coogan}, \citenamefont {Hezaveh},\ and\ \citenamefont {Perreault-Levasseur}}]{Lemos2023CoverageTest}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Lemos}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Coogan}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Hezaveh}},\ and\ \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Perreault-Levasseur}},\ }in\ \href@noop {} {\emph {\bibinfo {booktitle} {International Conference on Machine Learning}}}\ (\bibinfo {organization} {PMLR},\ \bibinfo {year} {2023})\ pp.\ \bibinfo {pages} {19256--19273}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {{CDF Collaboration}}(2022)}]{CDF2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibnamefont {{CDF Collaboration}}},\ }\bibfield  {title} {\emph {\bibinfo {title} {High-precision measurement of the <i>w</i> boson mass with the cdf ii detector}},\ }\href {https://doi.org/10.1126/science.abk1781} {\bibfield  {journal} {\bibinfo  {journal} {Science}\ }\textbf {\bibinfo {volume} {376}},\ \bibinfo {pages} {170--176} (\bibinfo {year} {2022})},\ \Eprint {https://arxiv.org/abs/https://www.science.org/doi/pdf/10.1126/science.abk1781} {https://www.science.org/doi/pdf/10.1126/science.abk1781} \BibitemShut {NoStop}%
\end{thebibliography}%

```

5. **Author Information:**
- Lead Author: {'name': 'Harry T. J. Bevins'}
- Full Authors List:
```yaml
Harry Bevins:
  coi:
    start: 2023-10-01
    thesis: null
  phd:
    start: 2019-10-01
    end: 2023-03-31
    supervisors:
    - Will Handley
    - Eloy de Lera Acedo
    - Anastasia Fialkov
    thesis: A Machine Learning-enhanced Toolbox for Bayesian 21-cm Data Analysis and
      Constraints on the Astrophysics of the Early Universe
  original_image: images/originals/harry_bevins.jpeg
  image: /assets/group/images/harry_bevins.jpg
  links:
    Webpage: https://htjb.github.io/
    GitHub: https://github.com/htjb
    ADS: https://ui.adsabs.harvard.edu/search/q=author%3A%22Bevins%2C%20H.%20T.%20J.%22&sort=date%20desc%2C%20bibcode%20desc&p_=0
    Publons: https://publons.com/researcher/5239833/harry-bevins/
  destination:
    2023-04-01: Postdoc in Cambridge (Eloy)
    2023-10-01: Cambridge Kavli Fellowship
Will Handley:
  pi:
    start: 2020-10-01
    thesis: null
  postdoc:
    start: 2016-10-01
    end: 2020-10-01
    thesis: null
  phd:
    start: 2012-10-01
    end: 2016-09-30
    supervisors:
    - Anthony Lasenby
    - Mike Hobson
    thesis: 'Kinetic initial conditions for inflation: theory, observation and methods'
  original_image: images/originals/will_handley.jpeg
  image: /assets/group/images/will_handley.jpg
  links:
    Webpage: https://willhandley.co.uk
Thomas Gessey-Jones:
  postdoc:
    start: 2024-04-01
    end: 2024-08-04
    thesis: null
  phd:
    start: 2020-10-01
    end: 2024-03-31
    supervisors:
    - Eloy de Lera Acedo
    - Anastasia Fialkov
    - Will Handley
    thesis: 'Probing the First Stars with the 21-cm Signal: Theory, Methods, and Forecasts'
  partiii:
    start: 2019-10-01
    end: 2020-06-01
    supervisors:
    - Will Handley
    thesis: Initial Conditions Before Inflation
  original_image: images/originals/thomas_gessey-jones.jpg
  image: /assets/group/images/thomas_gessey-jones.jpg
  links:
    Group webpage: https://www.cavendishradiocosmology.com/
    arXiv: https://arxiv.org/search/?query=T+Gessey-Jones&searchtype=all&abstracts=show&order=-announced_date_first&size=50
  destination:
    2024-08-05: <a href="https://www.physicx.ai/">PhysicsX</a>

```
This YAML file provides a concise snapshot of an academic research group. It lists members by name along with their academic rolesâ€”ranging from Part III and summer projects to MPhil, PhD, and postdoctoral positionsâ€”with corresponding dates, thesis topics, and supervisor details. Supplementary metadata includes image paths and links to personal or departmental webpages. A dedicated "coi" section profiles senior researchers, highlighting the groupâ€™s collaborative mentoring network and career trajectories in cosmology, astrophysics, and Bayesian data analysis.



====================================================================================
Final Output Instructions
====================================================================================

- Combine all data sources to create a seamless, engaging narrative.
- Follow the exact Markdown output format provided at the top.
- Do not include any extra explanation, commentary, or wrapping beyond the specified Markdown.
- Validate that every bibliographic reference with a DOI or arXiv identifier is converted into a Markdown link as per the examples.
- Validate that every Markdown author link corresponds to a link in the author information block.
- Before finalizing, confirm that no LaTeX citation commands or other undesired formatting remain.
- Before finalizing, confirm that the link to the paper itself [2407.15478](https://arxiv.org/abs/2407.15478) is featured in the first sentence.

Generate only the final Markdown output that meets all these requirements.

{% endraw %}